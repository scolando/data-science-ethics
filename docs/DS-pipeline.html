<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Data Science Ethics – The Data Science Ethics Lifecycle</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./images/favicon.ico" rel="icon">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/iconify-2.1.0/iconify-icon.min.js"></script>
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": "tree",
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="site_libs/core-js-2.5.3/shim.min.js"></script>
<script src="site_libs/react-17.0.0/react.min.js"></script>
<script src="site_libs/react-17.0.0/react-dom.min.js"></script>
<script src="site_libs/reactwidget-1.0.0/react-tools.js"></script>
<script src="site_libs/htmlwidgets-1.6.2/htmlwidgets.js"></script>
<link href="site_libs/reactable-0.4.4/reactable.css" rel="stylesheet">
<script src="site_libs/reactable-binding-0.4.4/reactable.js"></script>


</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./images/favicon.ico" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Data Science Ethics</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-intro-to-data-science-ethics" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Intro to Data Science Ethics</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-intro-to-data-science-ethics">    
        <li>
    <a class="dropdown-item" href="./Intro-DS-ethics.html">
 <span class="dropdown-text">What is Data Science Ethics?</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Intro-DS-lifecycle.html">
 <span class="dropdown-text">The Data Science Lifecycle</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-inside-the-syllabi" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Inside the Syllabi</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-inside-the-syllabi">    
        <li>
    <a class="dropdown-item" href="./inside-syllabi.html">
 <span class="dropdown-text">Data Science Ethics Syllabi</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Common-Topics.html">
 <span class="dropdown-text">Most Common Syllabi Topics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./DS-pipeline.html">
 <span class="dropdown-text">Data Science Lifecycle Connections</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./Reading-Tags.html"> 
<span class="menu-text">Reading Lists</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Page Contents</h2>
   
  <ul>
  <li><a href="#common-syllabi-topics" id="toc-common-syllabi-topics" class="nav-link active" data-scroll-target="#common-syllabi-topics">Common Syllabi Topics</a></li>
  <li><a href="#ethics-topics-and-the-data-science-lifecycle" id="toc-ethics-topics-and-the-data-science-lifecycle" class="nav-link" data-scroll-target="#ethics-topics-and-the-data-science-lifecycle">Ethics Topics and the Data Science Lifecycle</a></li>
  <li><a href="#lifecycle-connections" id="toc-lifecycle-connections" class="nav-link" data-scroll-target="#lifecycle-connections">Lifecycle Connections</a>
  <ul class="collapse">
  <li><a href="#characterizations-of-data-and-data-science" id="toc-characterizations-of-data-and-data-science" class="nav-link" data-scroll-target="#characterizations-of-data-and-data-science">Characterizations of Data and Data Science</a></li>
  <li><a href="#alignment" id="toc-alignment" class="nav-link" data-scroll-target="#alignment">Alignment</a></li>
  <li><a href="#responsibility" id="toc-responsibility" class="nav-link" data-scroll-target="#responsibility">Responsibility</a>
  <ul class="collapse">
  <li><a href="#paradigmatic-connections" id="toc-paradigmatic-connections" class="nav-link" data-scroll-target="#paradigmatic-connections">Paradigmatic Connection(s)</a></li>
  <li><a href="#less-conventional-connections" id="toc-less-conventional-connections" class="nav-link" data-scroll-target="#less-conventional-connections">Less Conventional Connection(s)</a></li>
  </ul></li>
  <li><a href="#consent" id="toc-consent" class="nav-link" data-scroll-target="#consent">Consent</a>
  <ul class="collapse">
  <li><a href="#paradigmatic-connections-1" id="toc-paradigmatic-connections-1" class="nav-link" data-scroll-target="#paradigmatic-connections-1">Paradigmatic Connection(s)</a></li>
  <li><a href="#less-conventional-connections-1" id="toc-less-conventional-connections-1" class="nav-link" data-scroll-target="#less-conventional-connections-1">Less Conventional Connection(s)</a></li>
  </ul></li>
  <li><a href="#privacy" id="toc-privacy" class="nav-link" data-scroll-target="#privacy">Privacy</a>
  <ul class="collapse">
  <li><a href="#paradigmatic-connections-2" id="toc-paradigmatic-connections-2" class="nav-link" data-scroll-target="#paradigmatic-connections-2">Paradigmatic Connection(s)</a></li>
  <li><a href="#less-conventional-connections-2" id="toc-less-conventional-connections-2" class="nav-link" data-scroll-target="#less-conventional-connections-2">Less Conventional Connection(s)</a></li>
  </ul></li>
  <li><a href="#bias-fairness-justice" id="toc-bias-fairness-justice" class="nav-link" data-scroll-target="#bias-fairness-justice">Bias, Fairness, Justice</a>
  <ul class="collapse">
  <li><a href="#paradigmatic-connections-3" id="toc-paradigmatic-connections-3" class="nav-link" data-scroll-target="#paradigmatic-connections-3">Paradigmatic Connection(s)</a></li>
  <li><a href="#less-conventional-connections-3" id="toc-less-conventional-connections-3" class="nav-link" data-scroll-target="#less-conventional-connections-3">Less Conventional Connection(s)</a></li>
  </ul></li>
  <li><a href="#explainability-interpretability-transparency" id="toc-explainability-interpretability-transparency" class="nav-link" data-scroll-target="#explainability-interpretability-transparency">Explainability, Interpretability, Transparency</a>
  <ul class="collapse">
  <li><a href="#paradigmatic-connections-4" id="toc-paradigmatic-connections-4" class="nav-link" data-scroll-target="#paradigmatic-connections-4">Paradigmatic Connection(s)</a></li>
  <li><a href="#less-conventional-connections-4" id="toc-less-conventional-connections-4" class="nav-link" data-scroll-target="#less-conventional-connections-4">Less Conventional Connection(s)</a></li>
  </ul></li>
  <li><a href="#causation" id="toc-causation" class="nav-link" data-scroll-target="#causation">Causation</a>
  <ul class="collapse">
  <li><a href="#paradigmatic-connections-5" id="toc-paradigmatic-connections-5" class="nav-link" data-scroll-target="#paradigmatic-connections-5">Paradigmatic Connection(s)</a></li>
  <li><a href="#less-conventional-connections-5" id="toc-less-conventional-connections-5" class="nav-link" data-scroll-target="#less-conventional-connections-5">Less Conventional Connection(s)</a></li>
  </ul></li>
  <li><a href="#democracy-workplace-predictive-policing" id="toc-democracy-workplace-predictive-policing" class="nav-link" data-scroll-target="#democracy-workplace-predictive-policing">Democracy, Workplace, Predictive Policing</a>
  <ul class="collapse">
  <li><a href="#paradigmatic-connections-6" id="toc-paradigmatic-connections-6" class="nav-link" data-scroll-target="#paradigmatic-connections-6">Paradigmatic Connection(s)</a></li>
  <li><a href="#less-conventional-connections-6" id="toc-less-conventional-connections-6" class="nav-link" data-scroll-target="#less-conventional-connections-6">Less Conventional Connection(s)</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">The Data Science Ethics Lifecycle</h1>
<p class="subtitle lead">connecting the most common ethics topics from the data science ethics syllabi to the final data science lifecycle</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<hr>
<section id="common-syllabi-topics" class="level1">
<h1>Common Syllabi Topics</h1>
<hr>
<p><span style="color:#364f7a; background-color: #f2f8fc; border: 3px solid #f2f8fc; border-radius: 4px;"><strong>‘Most Common’ = has a count of 3 or more</strong></span></p>
<div class="cell" data-layout-align="center">
<div id="fig-common-topics" class="cell-output-display quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-common-topics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="htmlwidget-53eb842db2f4271a05d1" class="reactable html-widget " style="width:700px;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-53eb842db2f4271a05d1">{"x":{"tag":{"name":"Reactable","attribs":{"data":{"Syllabi_Topics":["Privacy","Bias","Fairness","Explainability","Workplace","Alignment","Transparency","Causation","Characterizations of Data and Data Science","Consent","Democracy","Interpretability","Justice","Predictive Policing","Responsibility"],"Count":[11,8,8,6,5,4,4,3,3,3,3,3,3,3,3]},"columns":[{"id":"Syllabi_Topics","name":"Syllabi Topic","type":"character"},{"id":"Count","name":"Count","type":"numeric"}],"searchable":true,"defaultPageSize":8,"showPagination":true,"highlight":true,"showSortable":true,"width":"700px","theme":{"highlightColor":"#FAF9F0","style":{"fontFamily":"Helvetica Neue","fontSize":"0.875em"},"rowHighlightStyle":{"border-left":"0.15em solid #f0ba55;"}},"dataKey":"8a384a6acb5ecbddc7a8140ad79e3911"},"children":[]},"class":"reactR_markup"},"evals":[],"jsHooks":[]}</script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-common-topics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Most Common Syllabi Topics Arranged in Descending Order by Count.
</figcaption>
</figure>
</div>
</div>
<hr>
</section>
<section id="ethics-topics-and-the-data-science-lifecycle" class="level1">
<h1>Ethics Topics and the Data Science Lifecycle</h1>
<hr>
<p>The rings with less opacity denote areas where there seems to be substantial overlap between common topics and the data science stage though these considerations are not “paradigmatic” ethical issues.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-Pipeline-Ethics-Alpha-new" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-Pipeline-Ethics-Alpha-new-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Pipeline-Ethics-Alpha-new.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-Pipeline-Ethics-Alpha-new-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Data science lifecycle overlayed with concentric circles. The opaque concentric circles represent paradigmatic connections between the common ethics topic from the course syllabi and the data science stages. The transparent arcs denote areas where there is a connection between the common syllabi topics and the data science stage, but the connection is less conventional.
</figcaption>
</figure>
</div>
</div>
</div>
<hr>
</section>
<section id="lifecycle-connections" class="level1">
<h1>Lifecycle Connections</h1>
<hr>
<p>On this page, we offer paradigmatic and less conventional examples that demonstrate how the most frequent ethics topics from the syllabi arise throughout the data science lifecycle. The subsections are ordered from the first paradigmatic connection between the ethics topic and a data science stage, starting from ``interactions with the world” and then proceeding counterclockwise around the data science lifecycle. When understanding why ethical issues arise and are salient in a particular case, it is often beneficial to reflect on our intuitions in the case (e.g., that plagiarizing a school paper is morally impermissible). However, as also seen in the plagiarism case, explaining our intuitions involves developing a well-defended moral principle which often requires us to critically examine the validity of various moral principles (e.g., that deception is always morally impermissible) and then either scrap or revise the moral principles accordingly. Given the nuances of the ethical issues that arise in data science and ongoing discussions in philosophy about them, we direct the reader to our website’s reading lists (linked in each subsection’s header) to further explore the intricacies and applications of the ethics topics to data science.</p>
<hr>
<section id="characterizations-of-data-and-data-science" class="level2">
<h2 class="anchored" data-anchor-id="characterizations-of-data-and-data-science">Characterizations of Data and Data Science</h2>
<p>As mentioned on the <a href="Intro-DS-lifecycle.html">data science lifecycle page</a>, the choice of how to characterize data and data science is value-laden as it reflects a particular interpretation of knowledge from data and data models. For instance, if we view data as a direct representation of the world, we might overlook biases or other ethical issues that arise during the collection or data processing stages. On the other hand, if we view data and data models as context-dependent, then we can acknowledge that ethical issues, like algorithmic bias, can arise during the data collection and processing stages. In turn, characterizations of data and data science influence every stage of the data science lifecycle.</p>
<div class="link-2">
<section id="characterizations-of-data-and-data-science-readings" class="level4 link-2-header">
<h4 class="anchored" data-anchor-id="characterizations-of-data-and-data-science-readings"><iconify-icon inline="" icon="ep:reading" aria-label="Icon reading from ep Iconify.design set." title="Icon reading from ep Iconify.design set."></iconify-icon> <a href="./readings/Characterizations.html" target="_blank">Characterizations of Data and Data Science Readings</a></h4>
</section>
</div>
</section>
<section id="alignment" class="level2">
<h2 class="anchored" data-anchor-id="alignment">Alignment</h2>
<p>Alignment focuses on whether (and if so, how) our moral values are reflected in our current data science practices. Given that potentially morally charged decision points exist throughout data science (see <a href="Intro-DS-ethics.html">what is data science ethics?</a>), alignment is also an important ethics topic at every stage of the data science lifecycle.</p>
<div class="link-2">
<section id="alignment-readings" class="level4 link-2-header">
<h4 class="anchored" data-anchor-id="alignment-readings"><iconify-icon inline="" icon="ep:reading" aria-label="Icon reading from ep Iconify.design set." title="Icon reading from ep Iconify.design set."></iconify-icon> <a href="./readings/Alignment.html" target="_blank">Alignment Readings</a></h4>
</section>
</div>
<hr>
</section>
<section id="responsibility" class="level2">
<h2 class="anchored" data-anchor-id="responsibility">Responsibility</h2>
<p>While both moral and legal responsibility are important considerations in data science, we focus here on moral responsibility. Again, an individual might be morally responsible for their behavior, even if they would not be legally responsible for it (e.g., an individual might be morally responsible for plagiarizing a school paper but not legally responsible for it since the act of plagiarism is not against the law).</p>
<section id="paradigmatic-connections" class="level3">
<h3 class="anchored" data-anchor-id="paradigmatic-connections">Paradigmatic Connection(s)</h3>
<p>Discussions of moral responsibility in data science typically concern model deployment and “interactions with the world”. For example, Amazon was held morally responsible for deploying a hiring algorithm that was biased against female applicants <span class="citation" data-cites="Amazon">(<a href="#ref-Amazon" role="doc-biblioref">Dastin, 2018</a>)</span>. Moral responsibility also arises when building data models. For instance, it seems reasonable to contend that if another company had created Amazon’s faulty hiring algorithm, then that company would also be morally responsible, alongside Amazon, for the biased results if they did not adequately define where the model should be used or who should use it.</p>
<p>There are also several case studies (in data science and beyond) where people are morally responsible for failing to obtain informed consent when collecting personal information (i.e., during “interactions with the world”). Some examples include the collection of HeLa cells<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> and the commercialization of social media users’ data without obtaining their informed consent.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
</section>
<section id="less-conventional-connections" class="level3">
<h3 class="anchored" data-anchor-id="less-conventional-connections">Less Conventional Connection(s)</h3>
<p>Though less commonly thought about, moral responsibility is also relevant during data processing (i.e., between “interactions with the world” and “data”). Specifically, it seems reasonable to hold data scientists morally responsible for the moral harms that arise from their data cleaning or storage practices. For example, if a data scientist stored personal data in a foreseeably faulty database, they would be at least partially morally responsible for any data leakages. Similarly, if the data scientist who was supposed to remove identifiers from the data was negligent, they would have (at least some) moral responsibility for the ethical repercussions that arise from the data not being adequately anonymized.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div class="link-2">
<section id="responsibility-readings" class="level4 link-2-header">
<h4 class="anchored" data-anchor-id="responsibility-readings"><iconify-icon inline="" icon="ep:reading" aria-label="Icon reading from ep Iconify.design set." title="Icon reading from ep Iconify.design set."></iconify-icon> <a href="./readings/Responsibility.html" target="_blank">Responsibility Readings</a></h4>
</section>
</div>
<hr>
</section>
</section>
<section id="consent" class="level2">
<h2 class="anchored" data-anchor-id="consent">Consent</h2>
<section id="paradigmatic-connections-1" class="level3">
<h3 class="anchored" data-anchor-id="paradigmatic-connections-1">Paradigmatic Connection(s)</h3>
<p>Generally, when people think about informed consent in data science, they think about it during data collection (i.e., during ``interactions with the world”). That is, they consider whether the researcher or company has gathered informed consent when collecting people’s data. When researchers or companies get permission to collect people’s data, they also typically ask for consent to use it in a specific capacity later in the data science lifecycle (e.g., to build data models, store it in a database, or share with another company) given that obtaining a person’s informed consent is often essential for respecting their autonomy <span class="citation" data-cites="sep-informed-consent">(<a href="#ref-sep-informed-consent" role="doc-biblioref">Eyal, 2019</a>)</span>.</p>
</section>
<section id="less-conventional-connections-1" class="level3">
<h3 class="anchored" data-anchor-id="less-conventional-connections-1">Less Conventional Connection(s)</h3>
<p>While less conventional, issues of consent also arise when applying insights from data models to future interactions with an individual, even if none of the individual’s data was used to build (or test) the data model. For example, suppose that a job site creates a data model that predicts that people from a certain demographic group are more likely to interact with a nannying job post than a construction job post. A new person from that demographic group then engages with the job site. Based on the predictive model, the social media platform shows the nannying job post to them instead of the construction job post.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> It seems important for the social media company to obtain the new user’s informed consent to use the predictive model on them, given that the predictive model undermines their autonomy in some capacity. Namely, using the data model on the new user restricts them from seeing that certain jobs are available.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<div class="link-2">
<section id="consent-readings" class="level4 link-2-header">
<h4 class="anchored" data-anchor-id="consent-readings"><iconify-icon inline="" icon="ep:reading" aria-label="Icon reading from ep Iconify.design set." title="Icon reading from ep Iconify.design set."></iconify-icon> <a href="./readings/Consent.html" target="_blank">Consent Readings</a></h4>
</section>
</div>
<hr>
</section>
</section>
<section id="privacy" class="level2">
<h2 class="anchored" data-anchor-id="privacy">Privacy</h2>
<section id="paradigmatic-connections-2" class="level3">
<h3 class="anchored" data-anchor-id="paradigmatic-connections-2">Paradigmatic Connection(s)</h3>
<p>Privacy is often connected to data science between interactions with the world and data processing. For example, university researchers posted profile data from the OkCupid dating site to an open data repository in 2016 <span class="citation" data-cites="OkCupid">(<a href="#ref-OkCupid" role="doc-biblioref">Woollacott, 2016</a>)</span>. The data revealed intimate details about more than 70,000 users, including their usernames, sexual preferences, and personal opinions <span class="citation" data-cites="OkCupid">(<a href="#ref-OkCupid" role="doc-biblioref">Woollacott, 2016</a>)</span>. Around 30% of the profiles were identifiable, meaning that those profiles could be connected to their real name <span class="citation" data-cites="OkCupid">(<a href="#ref-OkCupid" role="doc-biblioref">Woollacott, 2016</a>)</span>. The researchers’ violation of the OkCupid users’ privacy seems morally problematic. As explained in <span class="citation" data-cites="sep-privacy">Roessler &amp; DeCew (<a href="#ref-sep-privacy" role="doc-biblioref">2023</a>)</span>, one reason why violating users’ privacy is morally problematic in this case is that it endangers the users’ abilities to control their relationships with others. That is, privacy is a way of ``modulating” our degrees of friendship with others, i.e., we would share more personal details about our life with someone we are better friends with <span class="citation" data-cites="sep-privacy">(<a href="#ref-sep-privacy" role="doc-biblioref">Roessler &amp; DeCew, 2023</a>)</span>. Additionally, some philosophers contend that the right to privacy is grounded in the right to autonomy (e.g., rights over one’s personal property and own body) <span class="citation" data-cites="sep-privacy">(<a href="#ref-sep-privacy" role="doc-biblioref">Roessler &amp; DeCew, 2023</a>)</span>.</p>
</section>
<section id="less-conventional-connections-2" class="level3">
<h3 class="anchored" data-anchor-id="less-conventional-connections-2">Less Conventional Connection(s)</h3>
<p>Worries about privacy can resurface when using insights from a data model to inform our future interactions with the world. For instance, suppose that a company’s data model predicts that an applicant is unqualified for a job. The company decides to share this prediction with a list of other major employers. There is an intuitive sense in which publicizing the model’s prediction to several other employers seems morally problematic, given that it entails sharing personal information about the applicant without their consent. However, would it be unethical for a boss at one company to share their belief that the person is unqualified for a job with their friend, who is a boss at another major company? It seems to be less morally tenuous even though the friend sharing their evaluation of the applicant with their friend still entails sharing personal information about the applicant without their consent. To explain our difference in intuitions in these two cases, we need a well-defended moral principle about what grounds someone’s right to privacy.</p>
<p>One justification for our difference in intuitions between the two cases is that there is a difference in scalability and damage in the algorithm versus the friend case. In her book, <em>Weapons of Math Destruction</em>, Cathy O’Neil breaks down different algorithms in terms of their opacity, scalability (pernicious feedback loops), and damage (ability to grow exponentially). She puts forward a moral principle to determine whether an algorithm is a <em>Weapon of Math Destruction</em>, in which case, she argues, it should not be used <span class="citation" data-cites="oneil2016">(<a href="#ref-oneil2016" role="doc-biblioref">O’Neil, 2016</a>)</span>. Avoiding pernicious feedback loops is one such strategy to ground privacy concerns and explain the difference in intuitions between the algorithm (which has a scalable pernicious feedback loop) and the friend case (which doesn’t).</p>
<div class="link-2">
<section id="privacy-readings" class="level4 link-2-header">
<h4 class="anchored" data-anchor-id="privacy-readings"><iconify-icon inline="" icon="ep:reading" aria-label="Icon reading from ep Iconify.design set." title="Icon reading from ep Iconify.design set."></iconify-icon> <a href="./readings/Privacy.html" target="_blank">Privacy Readings</a></h4>
</section>
</div>
<hr>
</section>
</section>
<section id="bias-fairness-justice" class="level2">
<h2 class="anchored" data-anchor-id="bias-fairness-justice">Bias, Fairness, Justice</h2>
<section id="paradigmatic-connections-3" class="level3">
<h3 class="anchored" data-anchor-id="paradigmatic-connections-3">Paradigmatic Connection(s)</h3>
<p>There are many cases of biased, unfair, and unjust data models. One such example is Amazon’s now-scrapped hiring algorithm, which was critiqued for being biased against female applicants <span class="citation" data-cites="Amazon">(<a href="#ref-Amazon" role="doc-biblioref">Dastin, 2018</a>)</span>. The algorithm’s goal was to identify ‘ideal candidates’ for technical positions at Amazon from hundreds of resumes submitted. Here, ‘ideal candidates’ were considered those whose resumes were most similar to resumes that had been previously submitted to Amazon over the last ten years. However, given that the technology industry is heavily male-dominated, most of these resumes came from male applicants, and consequently, the algorithm’s predictions turned out to be biased against women <span class="citation" data-cites="Amazon">(<a href="#ref-Amazon" role="doc-biblioref">Dastin, 2018</a>)</span>. For example, the algorithm penalized resumes with the word ‘women’s’ in it (e.g., ‘women’s cross country team captain’ or ‘women’s union staff member’) as well as graduates from two all-women’s colleges <span class="citation" data-cites="Amazon">(<a href="#ref-Amazon" role="doc-biblioref">Dastin, 2018</a>)</span>. Amazon’s algorithm seems unfair to female applicants. Namely, the algorithm wrongfully discriminated against female applicants by using a success metric (i.e., the similarity between the applicant’s resume and previously submitted resumes) that systematically overlooks well-qualified female applicants in virtue of their gender identity. However, as discussed in <a href="intro-DS-ethics.qmd">what is data science ethics?</a>, it is unclear how to evaluate fairness in models like Amazon’s now-scrapped hiring algorithm and, with that, how exactly to mitigate any unfairness in such models.</p>
<p>Moreover, it seems conceivable that even if Amazon improved the success metric, its hiring algorithm would still be biased against female applicants in virtue of there being a gender bias in the training data (i.e., model’s input). The saying “garbage in, garbage out” encapsulates the commonly seen connection between bias, fairness, justice, and data modeling. That is, the saying “garbage in, garbage out” notes that if the data used to build the data model was biased against group X, then the model’s predictions would be biased against group X and could lead to unfair (and/or unjust) outcomes for group X if the model’s predictions influence decision-making.</p>
<p>Beyond data modeling, issues of bias, fairness, and justice also emerge during ``interactions with the world”. For instance, suppose a data scientist wants to model the average number of hours in the hospital after giving birth but only surveys white females. We would consider the dataset biased towards white women and consequently be cautious about generalizing the data scientist’s findings to people in the population who are not white women.</p>
</section>
<section id="less-conventional-connections-3" class="level3">
<h3 class="anchored" data-anchor-id="less-conventional-connections-3">Less Conventional Connection(s)</h3>
<p>However, issues of bias, fairness, and justice are crucial to consider at every stage of the data science lifecycle. For example, we might completely drop observations with missing values when processing the data. Yet, dropping those values can create biases in our data and subsequent analyses if they are not missing at random.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> Bias, fairness, and justice can also come into play when insights from a data model influence our future interactions with our world. For instance, it seems unfair (and/or unjust) to only give a nannying job ad to women because an algorithm found that women were substantially more likely than men to click on nannying job ads.</p>
<div class="link-2">
<section id="bias-fairness-and-justice-readings" class="level4 link-2-header">
<h4 class="anchored" data-anchor-id="bias-fairness-and-justice-readings"><iconify-icon inline="" icon="ep:reading" aria-label="Icon reading from ep Iconify.design set." title="Icon reading from ep Iconify.design set."></iconify-icon> <a href="./readings/Bias.html" target="_blank">Bias, Fairness, and Justice Readings</a></h4>
</section>
</div>
<hr>
</section>
</section>
<section id="explainability-interpretability-transparency" class="level2">
<h2 class="anchored" data-anchor-id="explainability-interpretability-transparency">Explainability, Interpretability, Transparency</h2>
<p>A common complaint about data models, particularly more advanced ones, is that they are black boxes. In this subsection, we focus mainly on the connections between the lifecycle and explainability. However, the connections are similar to those for transparency and interpretability, given all three concepts share the common goal of making data models and their predictions more understandable to stakeholders.</p>
<section id="paradigmatic-connections-4" class="level3">
<h3 class="anchored" data-anchor-id="paradigmatic-connections-4">Paradigmatic Connection(s)</h3>
<p>In the model deployment stage, where predictions about individuals or groups are made, a reasonable ethical expectation is that the model is understandable to human stakeholders. One reason for this expectation is that if the model is explainable, then we can verify that the model is fair. For example, if a convicted person’s bail is set (using an algorithmic recommendation) higher than they think it should be, it seems fair for the individual to demand and expect an explanation for the algorithm’s recommendation in order to ensure that sensitive social attributes like race, gender, or socioeconomic status did not impact the algorithm’s prediction. Similarly, stakeholders might also demand that the algorithm’s parameters be transparent in order to see which variables influence the model’s predictions and, in particular, see whether the algorithm uses sensitive social attributes to make its predictions. The ethical expectation that data models are understandable to human stakeholders is often referred to as the “right to an explanation.” This expectation is echoed in legal documents such as the European Union’s General Data Protection Regulation (GDPR), which states that an individual has the right to ``obtain an explanation” for any automated decision made about them <span class="citation" data-cites="Goodman2017">(<a href="#ref-Goodman2017" role="doc-biblioref">Goodman &amp; Flaxman, 2017</a>)</span>.</p>
</section>
<section id="less-conventional-connections-4" class="level3">
<h3 class="anchored" data-anchor-id="less-conventional-connections-4">Less Conventional Connection(s)</h3>
<p>While not mentioned as often, the “right to an explanation” is also important to consider when insights from a data model influence future interactions with the world. For instance, suppose that law enforcement starts heavily policing Neighborhood A relative to Neighborhood B because a data model found that the people in Neighborhood A are more likely to be convicted of a crime than the people in Neighborhood B. It seems that the people in Neighborhood A have a right to understand why they are being policed more than the people in Neighborhood B. Like in the paradigmatic example, one reason for why the people in Neighborhood A seem to have a “right to an explanation” in this case is that explainability is often necessary to ensure that the model does not use sensitive social attributes to make its predictions. However, some philosophers note that human decision-makers are also black boxes with respect to how they arrive at their decisions. For instance, even if a court judge gives justification for their sentencing, it is not clear that the reason they give is the only reason for their decision or even is a reason for their decision at all (e.g., people can be subconsciously influenced by implicit biases) <span class="citation" data-cites="Gunther2022">(<a href="#ref-Gunther2022" role="doc-biblioref">Günther &amp; Kasirzadeh, 2022</a>)</span>. As such, one question within philosophy is whether we have a “right to an explanation” when it comes to data models, and if so, why do we have such a “right to an explanation” when it seems to hold algorithms to a higher standard than human decision-makers?</p>
<div class="link-2">
<section id="explainability-interpretability-and-transparency-readings" class="level4 link-2-header">
<h4 class="anchored" data-anchor-id="explainability-interpretability-and-transparency-readings"><iconify-icon inline="" icon="ep:reading" aria-label="Icon reading from ep Iconify.design set." title="Icon reading from ep Iconify.design set."></iconify-icon> <a href="./readings/Explainability.html" target="_blank">Explainability, Interpretability, and Transparency Readings</a></h4>
</section>
</div>
<hr>
</section>
</section>
<section id="causation" class="level2">
<h2 class="anchored" data-anchor-id="causation">Causation</h2>
<section id="paradigmatic-connections-5" class="level3">
<h3 class="anchored" data-anchor-id="paradigmatic-connections-5">Paradigmatic Connection(s)</h3>
<p>As early as introductory statistics courses, “correlation does not imply causation” is emphasized. The topic of causation is prominent in many data science ethics courses because mistakenly claiming causation can be morally pernicious when attempting to interpret knowledge from a data model. Most current data models can only identify correlations between the predictor variables and the response variable rather than causal relationships (n.b., there are also centuries worth of philosophical debates about how to define causation).<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p>Incorrectly interpreting causation between variables can have substantial moral repercussions during model deployment. For instance, suppose we have a logistic model that predicts whether a person will drop out of high school. Our model finds a positive association between having a first language other than English and the expected probability of dropping out of high school. There are several confounding variables, like socioeconomic status and availability of academic opportunities, which explain the identified positive association. However, imagine that a person sees our model and, from it, concludes that having a first language other than English <em>causes</em> a higher probability of dropping out of high school. As a result of mistakenly drawing causal claims from the model, they might advocate for English-only policies or develop prejudiced beliefs against people whose first language is not English.</p>
</section>
<section id="less-conventional-connections-5" class="level3">
<h3 class="anchored" data-anchor-id="less-conventional-connections-5">Less Conventional Connection(s)</h3>
<p>Moral implications surrounding causation can also arise when building causal inference models. For example, imagine there is a group of researchers who want to understand how a patient’s race influences their wait time in an emergency room. Answering the wait time question would involve evaluating whether the following counterfactual is true: if a patient was a member of racial group X instead of racial group Y, then their ER wait time would be different. One way the researchers might try to evaluate this counterfactual is by collecting data that contains background information (e.g., race) and the wait time at the hospital for each patient. The data would be used to estimate how changing only the ‘race’ variable for a patient would change their wait time. Yet, <span class="citation" data-cites="causal-inference-worries">Atoosa &amp; Smart (<a href="#ref-causal-inference-worries" role="doc-biblioref">2021</a>)</span> note that changing only the ‘race’ variable endorses an essentialist view of race that fails to acknowledge how race is socially constructed. Essentialist views of variables like race are harmful because they ignore the complex social, historical, and political factors that shape individuals’ experiences. As a result, essentialist views can often lead to overgeneralizations about social groups and even wrongful discrimination against them <span class="citation" data-cites="essentialism-harm">(<a href="#ref-essentialism-harm" role="doc-biblioref">Phillips, 2010</a>)</span>. Worries about how to thoughtfully conduct causal inference on social categories point to the importance of reflecting on philosophical questions, like what constitutes a specific social category (e.g., race, gender, sexuality, etc.) during model building.</p>
<div class="link-2">
<section id="causation-readings" class="level4 link-2-header">
<h4 class="anchored" data-anchor-id="causation-readings"><iconify-icon inline="" icon="ep:reading" aria-label="Icon reading from ep Iconify.design set." title="Icon reading from ep Iconify.design set."></iconify-icon> <a href="./readings/Causation.html" target="_blank">Causation Readings</a></h4>
</section>
</div>
<hr>
</section>
</section>
<section id="democracy-workplace-predictive-policing" class="level2">
<h2 class="anchored" data-anchor-id="democracy-workplace-predictive-policing">Democracy, Workplace, Predictive Policing</h2>
<section id="paradigmatic-connections-6" class="level3">
<h3 class="anchored" data-anchor-id="paradigmatic-connections-6">Paradigmatic Connection(s)</h3>
<p>Democracy, workplace, and predictive policing are all settings where data models are used and have exceptionally high moral stakes. As such, case studies related to democracy, workplace, and predictive policing are very common in the collated data science ethics syllabi and reading lists. Usually, when democracy, workplace, and predictive policing case studies are referenced, the focus is on model deployment. For instance, COMPAS is often brought up because it is deployed in a setting with high moral stakes, i.e., in US courtrooms to aid judges in making decisions about bond amounts and sentencing lengths for defendant <span class="citation" data-cites="COMPAS">(<a href="#ref-COMPAS" role="doc-biblioref">Angwin, Larson, Kirchner, &amp; Mattu, 2016</a>)</span>.</p>
<p>Yet, while there are moral implications for deploying data models in democracy, workplace, and predictive policing settings, it does not seem that creating such data models is inherently morally problematic. For example, suppose that a civil rights group creates an algorithm to predict a defendant’s likelihood of being convicted (like COMPAS does) but only uses the model to show that the criminal justice system is racially biased against Black defendants. Intuitively, building such a data model is not morally problematic. Rather, data models that predict a defendant’s recidivism risk are morally problematic when they are deployed in such a way that the model’s predictions impact people’s beliefs about a defendant’s recidivism risk and court outcomes.</p>
<p>The ethical theory of <em>consequentialism</em> can explain why the model’s deployment is relevant to its moral evaluation. According to <em>consequentialism</em>, only the consequences of an action ought to influence our moral assessment of it <span class="citation" data-cites="StanConsequentialism">(<a href="#ref-StanConsequentialism" role="doc-biblioref">Sinnott-Armstrong, 2023</a>)</span>. In the civil rights group and COMPAS examples, the consequences are different. COMPAS is being used to set bond amounts, sentence length, and parole, whereas the civil rights group algorithm is not being used in such a capacity. Another relevant difference between the civil rights group algorithm and COMPAS is that the civil rights group algorithm works <em>against</em> existing injustice rather than compounding it by aiming to elucidate the existing racial bias within the criminal justice system. Philosophy helps locate what exactly is morally problematic in a specific case (e.g., is it the data model’s predictions in themselves or how the model is deployed?), thereby helping us make our data science practices more ethical.</p>
</section>
<section id="less-conventional-connections-6" class="level3">
<h3 class="anchored" data-anchor-id="less-conventional-connections-6">Less Conventional Connection(s)</h3>
<p>Interpreting knowledge from model predictions can also lead to morally problematic interactions with the world within democracy, workplace, and predictive policing settings. For example, in her book, <em>Weapons of Math Destruction</em>, Cathy O’Neil considers PredPol, an algorithm that uses historical crime data to predict where crimes are most likely to occur. When police use PredPol, they can target neighborhoods based on where “nuisance” crimes (e.g., vagrancy, aggressive panhandling, selling and consuming small quantities of drugs) occur, which are unlikely to be recorded when there is not a police officer present . However, also notes that “nuisance” crimes are also much more common in impoverished neighborhoods. When the “nuisance” crime data is put into the predictive model, more police patrol impoverished neighborhoods, and arrests in those neighborhoods are more likely to occur. This creates a pernicious feedback loop because the policing of impoverished neighborhoods leads to arrests in the neighborhood, which ultimately justifies more policing of those neighborhoods <span class="citation" data-cites="oneil2016">(<a href="#ref-oneil2016" role="doc-biblioref">O’Neil, 2016</a>)</span>. As a result, more people are arrested for “nuisance” crimes, the majority of which come from impoverished neighborhoods and are Black or Hispanic due to racial segregation in cities <span class="citation" data-cites="oneil2016">(<a href="#ref-oneil2016" role="doc-biblioref">O’Neil, 2016</a>)</span>. Thus, using predictive policing models to inform future interactions with the world (i.e., where to send police) can create pernicious feedback loops that exacerbate existing racial injustices in the criminal justice system.</p>
<div class="link-2">
<section id="democracy-readings" class="level4 link-2-header">
<h4 class="anchored" data-anchor-id="democracy-readings"><iconify-icon inline="" icon="ep:reading" aria-label="Icon reading from ep Iconify.design set." title="Icon reading from ep Iconify.design set."></iconify-icon> <a href="./readings/Democracy.html" target="_blank">Democracy Readings</a></h4>
</section>
<section id="predictive-policing-readings" class="level4 link-2-header">
<h4 class="anchored" data-anchor-id="predictive-policing-readings"><iconify-icon inline="" icon="ep:reading" aria-label="Icon reading from ep Iconify.design set." title="Icon reading from ep Iconify.design set."></iconify-icon> <a href="./readings/Predictive-Policing.html" target="_blank">Predictive Policing Readings</a></h4>
</section>
<section id="workplace-readings" class="level4 link-2-header">
<h4 class="anchored" data-anchor-id="workplace-readings"><iconify-icon inline="" icon="ep:reading" aria-label="Icon reading from ep Iconify.design set." title="Icon reading from ep Iconify.design set."></iconify-icon> <a href="./readings/Workplace.html" target="_blank">Workplace Readings</a></h4>
</section>
</div>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-social-media-example" class="csl-entry" role="listitem">
Andreotta, A. J., Kirkham, N., &amp; Rizzi, M. (2021). <span>AI</span>, <span>B</span>ig <span>D</span>ata, and the future of consent. <em><span>AI</span> and <span>Society</span></em>, <em>37</em>(4), 1715–1728. <a href="https://doi.org/10.1007/s00146-021-01262-5">https://doi.org/10.1007/s00146-021-01262-5</a>
</div>
<div id="ref-COMPAS" class="csl-entry" role="listitem">
Angwin, J., Larson, J., Kirchner, L., &amp; Mattu, S. (2016). <em><span>M</span>achine <span>B</span>ias</em>. <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" class="uri">https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing</a>; ProPublica.
</div>
<div id="ref-causal-inference-worries" class="csl-entry" role="listitem">
Atoosa, A. K., &amp; Smart, A. (2021). The use and misuse of counterfactuals in ethical machine learning. <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>, 228–236. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/3442188.3445886">https://doi.org/10.1145/3442188.3445886</a>
</div>
<div id="ref-hiring-example" class="csl-entry" role="listitem">
Bogen, M. (2019). <em>All the ways hiring algorithms can introduce bias</em>. <a href="https://hbr.org/2019/05/all-the-ways-hiring-algorithms-can-introduce-bias" class="uri">https://hbr.org/2019/05/all-the-ways-hiring-algorithms-can-introduce-bias</a>.
</div>
<div id="ref-HeLa" class="csl-entry" role="listitem">
Callaway, E. (2013). Deal done over <span>HeLa</span> cell line. <em>Nature</em>, <em>500</em>(7461), 132–133. <a href="https://doi.org/10.1038/500132a">https://doi.org/10.1038/500132a</a>
</div>
<div id="ref-Amazon" class="csl-entry" role="listitem">
Dastin, J. (2018). <em><span>A</span>mazon scraps secret <span>A</span><span>I</span> recruiting tool that showed bias against women</em>. <a href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G" class="uri">https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G</a>; Reuters.
</div>
<div id="ref-sep-informed-consent" class="csl-entry" role="listitem">
Eyal, N. (2019). Informed consent. In E. N. Zalta (Ed.), <em>The <span>Stanford</span> encyclopedia of philosophy</em> (<span>S</span>pring 2019). <a href="https://plato.stanford.edu/archives/spr2019/entries/informed-consent/" class="uri">https://plato.stanford.edu/archives/spr2019/entries/informed-consent/</a>; Metaphysics Research Lab, Stanford University.
</div>
<div id="ref-Goodman2017" class="csl-entry" role="listitem">
Goodman, B., &amp; Flaxman, S. (2017). European <span>U</span>nion regulations on algorithmic decision making and a “right to explanation”. <em><span>AI</span> Magazine</em>, <em>38</em>(3), 50–57. <a href="https://doi.org/10.1609/aimag.v38i3.2741">https://doi.org/10.1609/aimag.v38i3.2741</a>
</div>
<div id="ref-Gunther2022" class="csl-entry" role="listitem">
Günther, M., &amp; Kasirzadeh, A. (2022). Algorithmic and human decision making: For a double standard of transparency. <em>AI and Society</em>, <em>37</em>(1), 375–381. <a href="https://doi.org/10.1007/s00146-021-01200-5">https://doi.org/10.1007/s00146-021-01200-5</a>
</div>
<div id="ref-non-random-imputation" class="csl-entry" role="listitem">
Kang, H. (2013). The prevention and handling of the missing data. <em>Korean Journal of Anesthesiology</em>, <em>64</em>(5), 402. <a href="https://doi.org/10.4097/kjae.2013.64.5.402">https://doi.org/10.4097/kjae.2013.64.5.402</a>
</div>
<div id="ref-oneil2016" class="csl-entry" role="listitem">
O’Neil, C. (2016). <em>Weapons of math destruction</em>. Crown Publishing Group.
</div>
<div id="ref-essentialism-harm" class="csl-entry" role="listitem">
Phillips, A. (2010). What’s wrong with essentialism? <em>Distinktion: Scandinavian Journal of Social Theory</em>, <em>11</em>, 47–60. <a href="https://doi.org/10.1080/1600910X.2010.9672755">https://doi.org/10.1080/1600910X.2010.9672755</a>
</div>
<div id="ref-sep-privacy" class="csl-entry" role="listitem">
Roessler, B., &amp; DeCew, J. (2023). <span>Privacy</span>. In E. N. Zalta &amp; U. Nodelman (Eds.), <em>The <span>Stanford</span> encyclopedia of philosophy</em> (<span>W</span>inter 2023). <a href="https://plato.stanford.edu/archives/win2023/entries/privacy/" class="uri">https://plato.stanford.edu/archives/win2023/entries/privacy/</a>; Metaphysics Research Lab, Stanford University.
</div>
<div id="ref-StanConsequentialism" class="csl-entry" role="listitem">
Sinnott-Armstrong, W. (2023). <span>Consequentialism</span>. In E. N. Zalta &amp; U. Nodelman (Eds.), <em>The <span>Stanford</span> encyclopedia of philosophy</em> (<span>W</span>inter 2023). <a href="https://plato.stanford.edu/archives/win2023/entries/consequentialism/" class="uri">https://plato.stanford.edu/archives/win2023/entries/consequentialism/</a>; Metaphysics Research Lab, Stanford University.
</div>
<div id="ref-towardsdatascienceCausalDiscovery" class="csl-entry" role="listitem">
Talebi, S. (2021). <em><span>C</span>ausal discovery</em>. <a href="https://towardsdatascience.com/causal-discovery-6858f9af6dcb" class="uri">https://towardsdatascience.com/causal-discovery-6858f9af6dcb</a>.
</div>
<div id="ref-OkCupid" class="csl-entry" role="listitem">
Woollacott, E. (2016). <em>70,000 <span>O</span>k<span>C</span>upid profiles leaked, intimate details and all</em>. <a href="https://www.forbes.com/sites/emmawoollacott/2016/05/13/intimate-data-of-70000-okcupid-users-released/?sh=2ac42f2f1e15" class="uri">https://www.forbes.com/sites/emmawoollacott/2016/05/13/intimate-data-of-70000-okcupid-users-released/?sh=2ac42f2f1e15</a>; Forbes.
</div>
</div>


</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>In 1951, cervical cancer cells from Henrietta Lacks were taken without her knowledge. Her cells and cell line, known colloquially as HeLa cells, have been widely used in science ever since <span class="citation" data-cites="HeLa">(<a href="#ref-HeLa" role="doc-biblioref">Callaway, 2013</a>)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>See <span class="citation" data-cites="social-media-example">Andreotta, Kirkham, &amp; Rizzi (<a href="#ref-social-media-example" role="doc-biblioref">2021</a>)</span> for issues with informed consent and social media.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>See <span class="citation" data-cites="OkCupid">Woollacott (<a href="#ref-OkCupid" role="doc-biblioref">2016</a>)</span> for an example of how moral responsibility can be relevant when failing to remove identifiers from data.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>This example is partially inspired by the examples in <span class="citation" data-cites="hiring-example">Bogen (<a href="#ref-hiring-example" role="doc-biblioref">2019</a>)</span>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>See <span class="citation" data-cites="sep-informed-consent">Eyal (<a href="#ref-sep-informed-consent" role="doc-biblioref">2019</a>)</span> for reasons beyond respecting a person’s autonomy why obtaining informed consent is morally important.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>This example is partially inspired by the discussion in <span class="citation" data-cites="non-random-imputation">Kang (<a href="#ref-non-random-imputation" role="doc-biblioref">2013</a>)</span>.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Also, see examples of how current data models are not yet able to accurately identify causation in <span class="citation" data-cites="towardsdatascienceCausalDiscovery">Talebi (<a href="#ref-towardsdatascienceCausalDiscovery" role="doc-biblioref">2021</a>)</span>.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/scolando\.github\.io\/data-science-ethics\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2024, <a href="https://scolando.github.io/personal-website/">Sara Colando</a> and <a href="https://hardin47.netlify.app">Jo Hardin</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://github.com/scolando/personal-website">
<p><iconify-icon inline="" icon="mdi:github" aria-label="Icon github from mdi Iconify.design set." title="Icon github from mdi Iconify.design set."></iconify-icon> Source Code</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://github.com/scolando/data-science-ethics/issues/new">
<p>Report an Issue</p>
</a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>