[
  {
    "objectID": "Reading-Tags.html",
    "href": "Reading-Tags.html",
    "title": "Reading Lists",
    "section": "",
    "text": "Alignment\n\n\nReadings on the moral alignment between human values and current data science practices.\n\n\n\n\n\n\n\n\n\n\nBias, Fairness, and Justice\n\n\nReadings on the normative concepts of bias, fairness, and justice and how they are relevant considerations in data science.\n\n\n\n\n\n\n\n\n\n\nCausation\n\n\nReadings on causation as it applies to data science, and more specifically data science ethics. A primary focus of these readings is causal inference and socially sensitive attributes (e.g., race and gender).\n\n\n\n\n\n\n\n\n\n\nCharacterizations of Data Science\n\n\nReadings on how to characterize data science and aritificial intelligence, and in particular, how it uses induction.\n\n\n\n\n\n\n\n\n\n\nConsent\n\n\nReadings on informed consent in data science practices, why it ethically matters, and how to grapple with the practical challenges of obtaining informed consent in data science.\n\n\n\n\n\n\n\n\n\n\nDemocracy\n\n\nReadings and case studies on the applications of data science in democracy and the ethical implications of using statistical models in such contexts.\n\n\n\n\n\n\n\n\n\n\nExplainability\n\n\nReadings on what is meant by “explainability” (and related terms like “transparency” and “interpretability”) in data science and to what extent acheiving explainabilty (or transparency or interpretability) in algorithms is morally important.\n\n\n\n\n\n\n\n\n\n\nPredictive Policing\n\n\nReadings and case studies on the applications of data science in predictive policing and the ethical implications of using statistical models to perform predictive policing.\n\n\n\n\n\n\n\n\n\n\nPrivacy\n\n\nReadings on privacy, why it matters, its relationship to consent, and case studies that emphasize both the importance and difficulty of ensuring privacy in data science.\n\n\n\n\n\n\n\n\n\n\nResponsibility\n\n\nReadings concerning moral responsibility in data science as well as some of the challenges in assessing who is morally responsible for data models and predictions.\n\n\n\n\n\n\n\n\n\n\nWorkplace\n\n\nReadings and case studies on the applications of data science in the workplace (e.g., in hiring or promotion) and the ethical implications of using statistical models in such contexts.\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "readings/Democracy.html",
    "href": "readings/Democracy.html",
    "title": "Democracy",
    "section": "",
    "text": "Title\nCitation"
  },
  {
    "objectID": "readings/Democracy.html#references",
    "href": "readings/Democracy.html#references",
    "title": "Democracy",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "readings/Alignment.html",
    "href": "readings/Alignment.html",
    "title": "Alignment",
    "section": "",
    "text": "Title\nCitation"
  },
  {
    "objectID": "readings/Alignment.html#references",
    "href": "readings/Alignment.html#references",
    "title": "Alignment",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "readings/Bias.html",
    "href": "readings/Bias.html",
    "title": "Bias, Fairness, and Justice",
    "section": "",
    "text": "Title\nCitation\n\n\n\n\nAre Algorithms Value-Free?\nJohnson (2023)\n\n\nAlgorithmic Bias: on the Implicit Biases of Social Technology\nJohnson (2020)\n\n\nAlgorithmic Bias: Senses, Sources, Solutions\nFazelpour & Danks (2021)\n\n\nFairness\n(sep-informed-consent?)\n\n\nJust Machines\nCastro (2022)\n\n\nBig Data and Compounding Injustice\nHellman (2023)\n\n\nOn the Site of Predictive Justice\nLazar & Stone (forthcoming)\n\n\nProceed with Caution\nZimmermann & Lee-Stronach (2021)\n\n\nSemantics Derived Automatically from Language Corpora Contain Human-like Biases\nCaliskan, Bryson, & Narayanan (2017)\n\n\nThe Algorithmic Leviathan: Arbitrariness, Fairness, and Opportunity in Algorithmic Decision-Making Systems\nCreel & Hellman (2022)"
  },
  {
    "objectID": "readings/Bias.html#references",
    "href": "readings/Bias.html#references",
    "title": "Bias, Fairness, and Justice",
    "section": "References",
    "text": "References\n\n\nCaliskan, A., Bryson, J., & Narayanan, A. (2017). Semantics derived automatically from language corpora contain human-like biases. Science, 356, 183–186. https://doi.org/10.1126/science.aal4230\n\n\nCastro, C. (2022). Just machines. Public Affairs Quarterly, 36(2), 163–183. https://doi.org/10.5406/21520542.36.2.04\n\n\nCreel, K., & Hellman, D. (2022). The algorithmic leviathan: Arbitrariness, fairness, and opportunity in algorithmic decision-making systems. Canadian Journal of Philosophy, 52(1), 26–43. https://doi.org/10.1017/can.2022.3\n\n\nFazelpour, S., & Danks, D. (2021). Algorithmic bias: Senses, sources, solutions. Philosophy Compass, 16(8), e12760. https://doi.org/10.1111/phc3.12760\n\n\nHellman, D. (2023). Big data and compounding injustice. Journal of Moral Philosophy, 21(1-2), 62–83. https://doi.org/10.1163/17455243-20234373\n\n\nJohnson, G. M. (2020). Algorithmic bias: On the implicit biases of social technology. Synthese, 198(10), 9941–9961. https://doi.org/10.1007/s11229-020-02696-y\n\n\nJohnson, G. M. (2023). Are algorithms value-free? Journal Moral Philosophy, 21(1-2), 1–35. https://doi.org/10.1163/17455243-20234372\n\n\nLazar, S., & Stone, J. (forthcoming). On the site of predictive justice. Noûs. Forthcoming. https://doi.org/10.1111/nous.12477\n\n\nZimmermann, A., & Lee-Stronach, C. (2021). Proceed with caution. Canadian Journal of Philosophy, (1), 6–25. https://doi.org/10.1017/can.2021.17"
  },
  {
    "objectID": "readings/Causation.html",
    "href": "readings/Causation.html",
    "title": "Causation",
    "section": "",
    "text": "Title\nCitation\n\n\n\n\nCausation\nScheines (n.d.)\n\n\nThe Problem of Induction (Stanford Encyclopedia of Philosophy)\nHenderson (2022)\n\n\nThe Use and Misuse of Counterfactuals in Ethical Machine Learning\nKasirzadeh & Smart (2021)\n\n\nEddie Murphy and the Dangers of Counterfactual Causal Thinking About Detecting Racial Discrimination\nKohler-Hausmann (2017)\n\n\nWhat is “Race” in Algorithmic Discrimination on the Basis of Race?\nHu (Forthcoming)"
  },
  {
    "objectID": "readings/Causation.html#references",
    "href": "readings/Causation.html#references",
    "title": "Causation",
    "section": "References",
    "text": "References\n\n\nHenderson, L. (2022). The Problem of Induction. In E. N. Zalta & U. Nodelman (Eds.), The Stanford encyclopedia of philosophy (Winter 2022). https://plato.stanford.edu/archives/win2022/entries/induction-problem/; Metaphysics Research Lab, Stanford University.\n\n\nHu, L. (Forthcoming). What’s ’race’ in algorithmic discrimination on the basis of race? Journal of Moral Philosophy.\n\n\nKasirzadeh, A., & Smart, A. (2021). The use and misuse of counterfactuals in ethical machine learning. Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 228–236. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3442188.3445886\n\n\nKohler-Hausmann, I. (2017). The dangers of counterfactual causal thinking about detecting racial discrimination. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.3050650\n\n\nScheines, R. (n.d.). Causation."
  },
  {
    "objectID": "readings/Characterizations.html",
    "href": "readings/Characterizations.html",
    "title": "Characterizations of Data Science",
    "section": "",
    "text": "Title\nCitation"
  },
  {
    "objectID": "readings/Characterizations.html#references",
    "href": "readings/Characterizations.html#references",
    "title": "Characterizations of Data Science",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "readings/Consent.html",
    "href": "readings/Consent.html",
    "title": "Consent",
    "section": "",
    "text": "Title\nCitation\n\n\n\n\nInformed Consent (Stanford Encyclopedia of Philosophy)\nEyal (2019)\n\n\nPrivacy Self-Management and the Consent Dilemma\nSolove (2012)\n\n\nThe Ethics of Consent: Theory and Practice\nMiller & Wertheimer (2010)\n\n\nMiddletown, a Study in Contemporary American Culture\nWolmarans & Voorhoeve (2022)\n\n\nA Belmont Report for Health Data\nWolmarans & Voorhoeve (2022)\n\n\nNaturalizing Coercion: The Tuskegee Experiments and the Laboratory Life of the Plantation\nWolmarans & Voorhoeve (2022)\n\n\nWhat Makes Personal Data Processing by Social Networking Services Permissible?\nWolmarans & Voorhoeve (2022)\n\n\nWhat’s Wrong with Automated Influence\nBenn & Lazar (2021)"
  },
  {
    "objectID": "readings/Consent.html#references",
    "href": "readings/Consent.html#references",
    "title": "Consent",
    "section": "References",
    "text": "References\n\n\nBenn, C., & Lazar, S. (2021). What’s wrong with automated influence. Canadian Journal of Philosophy, 52, 1–24. https://doi.org/10.1017/can.2021.23\n\n\nEyal, N. (2019). Informed Consent. In E. N. Zalta (Ed.), The Stanford encyclopedia of philosophy (Spring 2019). https://plato.stanford.edu/archives/spr2019/entries/informed-consent/; Metaphysics Research Lab, Stanford University.\n\n\nMiller, F. G., & Wertheimer, A. (2010). The ethics of consent: Theory and practice (pp. 1–430). https://doi.org/10.1093/acprof:oso/9780195335149.001.0001\n\n\nSolove, D. (2012). Privacy self-management and the consent dilemma. Harvard Law Review, 126.\n\n\nWolmarans, L., & Voorhoeve, A. (2022). What makes personal data processing by social networking services permissible? Canadian Journal of Philosophy, 52(1), 93–108. https://doi.org/10.1017/can.2022.4"
  },
  {
    "objectID": "readings/Explainability.html",
    "href": "readings/Explainability.html",
    "title": "Explainability",
    "section": "",
    "text": "Title\nCitation\n\n\n\n\nTransparency in Complex Computational Systems\n(sep-privacy?)\n\n\nHow the Machine “Thinks”: Understanding Opacity in Machine Learning Algorithms\n(sep-privacy?)\n\n\nAlgorithmic and Human Decision Making: For a Double Standard of Transparency\n(sep-privacy?)\n\n\nThe Right to an Explanation\n(sep-privacy?)\n\n\nThe Mythos of Model Interpretability\n(sep-privacy?)"
  },
  {
    "objectID": "readings/Explainability.html#explainability-transparency-and-interpretability-readings",
    "href": "readings/Explainability.html#explainability-transparency-and-interpretability-readings",
    "title": "Explainability",
    "section": "",
    "text": "Title\nCitation\n\n\n\n\nTransparency in Complex Computational Systems\n(sep-privacy?)\n\n\nHow the Machine “Thinks”: Understanding Opacity in Machine Learning Algorithms\n(sep-privacy?)\n\n\nAlgorithmic and Human Decision Making: For a Double Standard of Transparency\n(sep-privacy?)\n\n\nThe Right to an Explanation\n(sep-privacy?)\n\n\nThe Mythos of Model Interpretability\n(sep-privacy?)"
  },
  {
    "objectID": "readings/Explainability.html#references",
    "href": "readings/Explainability.html#references",
    "title": "Explainability",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "readings/Predictive-Policing.html",
    "href": "readings/Predictive-Policing.html",
    "title": "Predictive Policing",
    "section": "",
    "text": "Title\nCitation"
  },
  {
    "objectID": "readings/Predictive-Policing.html#references",
    "href": "readings/Predictive-Policing.html#references",
    "title": "Predictive Policing",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "readings/Privacy.html",
    "href": "readings/Privacy.html",
    "title": "Privacy",
    "section": "",
    "text": "Title\nCitation\n\n\n\n\nPrivacy (Stanford Encyclopedia of Philosophy)\nDeCew (2018)\n\n\nWhy Privacy is Important\nRachels (1975)\n\n\nWhy We Care about Privacy\nMcFarland (2012)\n\n\nPrivacy and Human Behavior in the Age of Information\nAcquisti, Brandimarte, & Loewenstein (2015)\n\n\nSurveillance and Capture: Two Models of Privacy\nAcquisti et al. (2015)\n\n\nFrom Individual to Group Privacy in Big Data Analytics\nMittelstadt (2017)\n\n\nA Modern Pascal’s Wager for Mass Electronic Surveillance\nDanks (2014)\n\n\nPrivacy and Paternalism: The Ethics of Student Data Collection\nCreel & Dixit (2022)\n\n\nBig Data’s End Run around Procedural Privacy Protections\nBarocas & Nissenbaum (2014)\n\n\nWhy ‘I Have Nothing to Hide’ is the Wrong Way to Think About Surveillance\nBarocas & Nissenbaum (2014)\n\n\nCan a Set of Equations keep U.S. Census Data Private?\nBarocas & Nissenbaum (2014)\n\n\nWhy ‘Anonymous’ Data Sometimes Isn’t\nSchneier (2007)"
  },
  {
    "objectID": "readings/Privacy.html#additional-privacy-readings",
    "href": "readings/Privacy.html#additional-privacy-readings",
    "title": "Privacy",
    "section": "Additional Privacy Readings",
    "text": "Additional Privacy Readings\n\nPhilosophy of Privacy and Digital Life\nNothing to Hide\nIt’s Not Privacy, and It’s Not Fair\nDigital Reputation in an Era of Runaway Data\nThe Surveillance Society\nRecommender Systems and Their Ethical Challenges"
  },
  {
    "objectID": "readings/Privacy.html#references",
    "href": "readings/Privacy.html#references",
    "title": "Privacy",
    "section": "References",
    "text": "References\n\n\nAcquisti, A., Brandimarte, L., & Loewenstein, G. (2015). Privacy and human behavior in the age of information. Science (New York, N.Y.), 347, 509–514. https://doi.org/10.1126/science.aaa1465\n\n\nBarocas, S., & Nissenbaum, H. (2014). Big data’s end run around procedural privacy protections. Communications of the ACM, 57, 31–33. https://doi.org/10.1145/2668897\n\n\nCreel, K., & Dixit, T. (2022). Privacy and Paternalism: The Ethics of Student Data Collection. https://thereader.mitpress.mit.edu/privacy-and-paternalism-the-ethics-of-student-data-collection/; The MIT Press Reader.\n\n\nDanks, D. (2014). A modern pascal’s wager for mass electronic surveillance. https://doi.org/10.1184/R1/6490751.V1\n\n\nDeCew, J. (2018). Privacy. In E. N. Zalta (Ed.), The Stanford encyclopedia of philosophy (Spring 2018). https://plato.stanford.edu/archives/spr2018/entries/privacy/; Metaphysics Research Lab, Stanford University.\n\n\nMcFarland, M. (2012). Why We Care about Privacy. https://www.scu.edu/ethics/focus-areas/internet-ethics/resources/why-we-care-about-privacy/; Markkula Center for Applied Ethics at Santa Clara University.\n\n\nMittelstadt, B. (2017). From individual to group privacy in big data analytics. Philosophy & Technology, 30. https://doi.org/10.1007/s13347-017-0253-7\n\n\nRachels, J. (1975). Why privacy is important. Philosophy & Public Affairs, 4(4), 323–333. Retrieved from http://www.jstor.org/stable/2265077\n\n\nSchneier, B. (2007). Why ’Anonymous’ Data Sometimes Isn’t. https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/; Wired."
  },
  {
    "objectID": "readings/Responsibility.html",
    "href": "readings/Responsibility.html",
    "title": "Responsibility",
    "section": "",
    "text": "Title\nCitation"
  },
  {
    "objectID": "readings/Responsibility.html#references",
    "href": "readings/Responsibility.html#references",
    "title": "Responsibility",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "readings/Workplace.html",
    "href": "readings/Workplace.html",
    "title": "Workplace",
    "section": "",
    "text": "Title\nCitation"
  },
  {
    "objectID": "readings/Workplace.html#references",
    "href": "readings/Workplace.html#references",
    "title": "Workplace",
    "section": "References",
    "text": "References"
  }
]