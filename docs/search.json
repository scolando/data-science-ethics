[
  {
    "objectID": "Reading-Tags.html",
    "href": "Reading-Tags.html",
    "title": "Reading Lists",
    "section": "",
    "text": "Alignment\n\n\nReadings on the moral alignment between human values and current data science practices.\n\n\n\n\n\n\n\n\n\n\nBias, Fairness, and Justice\n\n\nReadings on the normative concepts of bias, fairness, and justice and how they are relevant considerations in data science.\n\n\n\n\n\n\n\n\n\n\nCausation\n\n\nReadings on causation as it applies to data science, and more specifically data science ethics. A primary focus of these readings is causal inference and socially sensitive attributes (e.g., race and gender).\n\n\n\n\n\n\n\n\n\n\nCharacterizations of Data Science\n\n\nReadings on how to characterize data science and aritificial intelligence, and in particular, how it uses induction.\n\n\n\n\n\n\n\n\n\n\nConsent\n\n\nReadings on informed consent in data science practices, why it ethically matters, and how to grapple with the practical challenges of obtaining informed consent in data science.\n\n\n\n\n\n\n\n\n\n\nDemocracy\n\n\nReadings and case studies on the applications of data science in democracy and the ethical implications of using statistical models in such contexts.\n\n\n\n\n\n\n\n\n\n\nExplainability\n\n\nReadings on what is meant by “explainability” (and related terms like “transparency” and “interpretability”) in data science and to what extent acheiving explainabilty (or transparency or interpretability) in algorithms is morally important.\n\n\n\n\n\n\n\n\n\n\nPredictive Policing\n\n\nReadings and case studies on the applications of data science in predictive policing and the ethical implications of using statistical models to perform predictive policing.\n\n\n\n\n\n\n\n\n\n\nPrivacy\n\n\nReadings on privacy, why it matters, its relationship to consent, and case studies that emphasize both the importance and difficulty of ensuring privacy in data science.\n\n\n\n\n\n\n\n\n\n\nResponsibility\n\n\nReadings concerning moral responsibility in data science as well as some of the challenges in assessing who is morally responsible for data models and predictions.\n\n\n\n\n\n\n\n\n\n\nWorkplace\n\n\nReadings and case studies on the applications of data science in the workplace (e.g., in hiring or promotion) and the ethical implications of using statistical models in such contexts.\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "readings/Democracy.html",
    "href": "readings/Democracy.html",
    "title": "Democracy",
    "section": "",
    "text": "Title\nCitation"
  },
  {
    "objectID": "readings/Democracy.html#references",
    "href": "readings/Democracy.html#references",
    "title": "Democracy",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "readings/Alignment.html",
    "href": "readings/Alignment.html",
    "title": "Alignment",
    "section": "",
    "text": "Title\nCitation"
  },
  {
    "objectID": "readings/Alignment.html#references",
    "href": "readings/Alignment.html#references",
    "title": "Alignment",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "readings/Bias.html",
    "href": "readings/Bias.html",
    "title": "Bias, Fairness, and Justice",
    "section": "",
    "text": "Title\nCitation\n\n\n\n\nAre Algorithms Value-Free?\nJohnson (2023)\n\n\nAlgorithmic Bias: on the Implicit Biases of Social Technology\nJohnson (2020)\n\n\nAlgorithmic Bias: Senses, Sources, Solutions\nFazelpour & Danks (2021)\n\n\nFairness\n(sep-informed-consent?)\n\n\nJust Machines\nCastro (2022)\n\n\nBig Data and Compounding Injustice\nHellman (2023)\n\n\nOn the Site of Predictive Justice\nLazar & Stone (forthcoming)\n\n\nProceed with Caution\nZimmermann & Lee-Stronach (2021)\n\n\nSemantics Derived Automatically from Language Corpora Contain Human-like Biases\nCaliskan, Bryson, & Narayanan (2017)\n\n\nThe Algorithmic Leviathan: Arbitrariness, Fairness, and Opportunity in Algorithmic Decision-Making Systems\nCreel & Hellman (2022)"
  },
  {
    "objectID": "readings/Bias.html#references",
    "href": "readings/Bias.html#references",
    "title": "Bias, Fairness, and Justice",
    "section": "References",
    "text": "References\n\n\nCaliskan, A., Bryson, J., & Narayanan, A. (2017). Semantics derived automatically from language corpora contain human-like biases. Science, 356, 183–186. https://doi.org/10.1126/science.aal4230\n\n\nCastro, C. (2022). Just machines. Public Affairs Quarterly, 36(2), 163–183. https://doi.org/10.5406/21520542.36.2.04\n\n\nCreel, K., & Hellman, D. (2022). The algorithmic leviathan: Arbitrariness, fairness, and opportunity in algorithmic decision-making systems. Canadian Journal of Philosophy, 52(1), 26–43. https://doi.org/10.1017/can.2022.3\n\n\nFazelpour, S., & Danks, D. (2021). Algorithmic bias: Senses, sources, solutions. Philosophy Compass, 16(8), e12760. https://doi.org/10.1111/phc3.12760\n\n\nHellman, D. (2023). Big data and compounding injustice. Journal of Moral Philosophy, 21(1-2), 62–83. https://doi.org/10.1163/17455243-20234373\n\n\nJohnson, G. M. (2020). Algorithmic bias: On the implicit biases of social technology. Synthese, 198(10), 9941–9961. https://doi.org/10.1007/s11229-020-02696-y\n\n\nJohnson, G. M. (2023). Are algorithms value-free? Journal Moral Philosophy, 21(1-2), 1–35. https://doi.org/10.1163/17455243-20234372\n\n\nLazar, S., & Stone, J. (forthcoming). On the site of predictive justice. Noûs. Forthcoming. https://doi.org/10.1111/nous.12477\n\n\nZimmermann, A., & Lee-Stronach, C. (2021). Proceed with caution. Canadian Journal of Philosophy, (1), 6–25. https://doi.org/10.1017/can.2021.17"
  },
  {
    "objectID": "readings/Causation.html",
    "href": "readings/Causation.html",
    "title": "Causation",
    "section": "",
    "text": "Title\nCitation\n\n\n\n\nCausation\nScheines (n.d.)\n\n\nThe Problem of Induction (Stanford Encyclopedia of Philosophy)\nHenderson (2022)\n\n\nThe Use and Misuse of Counterfactuals in Ethical Machine Learning\nKasirzadeh & Smart (2021)\n\n\nEddie Murphy and the Dangers of Counterfactual Causal Thinking About Detecting Racial Discrimination\nKohler-Hausmann (2017)\n\n\nWhat is “Race” in Algorithmic Discrimination on the Basis of Race?\nHu (Forthcoming)"
  },
  {
    "objectID": "readings/Causation.html#references",
    "href": "readings/Causation.html#references",
    "title": "Causation",
    "section": "References",
    "text": "References\n\n\nHenderson, L. (2022). The Problem of Induction. In E. N. Zalta & U. Nodelman (Eds.), The Stanford encyclopedia of philosophy (Winter 2022). https://plato.stanford.edu/archives/win2022/entries/induction-problem/; Metaphysics Research Lab, Stanford University.\n\n\nHu, L. (Forthcoming). What’s ’race’ in algorithmic discrimination on the basis of race? Journal of Moral Philosophy.\n\n\nKasirzadeh, A., & Smart, A. (2021). The use and misuse of counterfactuals in ethical machine learning. Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 228–236. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3442188.3445886\n\n\nKohler-Hausmann, I. (2017). The dangers of counterfactual causal thinking about detecting racial discrimination. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.3050650\n\n\nScheines, R. (n.d.). Causation."
  },
  {
    "objectID": "readings/Characterizations.html",
    "href": "readings/Characterizations.html",
    "title": "Characterizations of Data Science",
    "section": "",
    "text": "Title\nCitation"
  },
  {
    "objectID": "readings/Characterizations.html#references",
    "href": "readings/Characterizations.html#references",
    "title": "Characterizations of Data Science",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "readings/Consent.html",
    "href": "readings/Consent.html",
    "title": "Consent",
    "section": "",
    "text": "Title\nCitation\n\n\n\n\nInformed Consent (Stanford Encyclopedia of Philosophy)\nEyal (2019)\n\n\nPrivacy Self-Management and the Consent Dilemma\nSolove (2012)\n\n\nThe Ethics of Consent: Theory and Practice\nMiller & Wertheimer (2010)\n\n\nMiddletown, a Study in Contemporary American Culture\nWolmarans & Voorhoeve (2022)\n\n\nA Belmont Report for Health Data\nWolmarans & Voorhoeve (2022)\n\n\nNaturalizing Coercion: The Tuskegee Experiments and the Laboratory Life of the Plantation\nWolmarans & Voorhoeve (2022)\n\n\nWhat Makes Personal Data Processing by Social Networking Services Permissible?\nWolmarans & Voorhoeve (2022)\n\n\nWhat’s Wrong with Automated Influence\nBenn & Lazar (2021)"
  },
  {
    "objectID": "readings/Consent.html#references",
    "href": "readings/Consent.html#references",
    "title": "Consent",
    "section": "References",
    "text": "References\n\n\nBenn, C., & Lazar, S. (2021). What’s wrong with automated influence. Canadian Journal of Philosophy, 52, 1–24. https://doi.org/10.1017/can.2021.23\n\n\nEyal, N. (2019). Informed Consent. In E. N. Zalta (Ed.), The Stanford encyclopedia of philosophy (Spring 2019). https://plato.stanford.edu/archives/spr2019/entries/informed-consent/; Metaphysics Research Lab, Stanford University.\n\n\nMiller, F. G., & Wertheimer, A. (2010). The ethics of consent: Theory and practice (pp. 1–430). https://doi.org/10.1093/acprof:oso/9780195335149.001.0001\n\n\nSolove, D. (2012). Privacy self-management and the consent dilemma. Harvard Law Review, 126.\n\n\nWolmarans, L., & Voorhoeve, A. (2022). What makes personal data processing by social networking services permissible? Canadian Journal of Philosophy, 52(1), 93–108. https://doi.org/10.1017/can.2022.4"
  },
  {
    "objectID": "readings/Explainability.html",
    "href": "readings/Explainability.html",
    "title": "Explainability",
    "section": "",
    "text": "Title\nCitation\n\n\n\n\nTransparency in Complex Computational Systems\n(sep-privacy?)\n\n\nHow the Machine “Thinks”: Understanding Opacity in Machine Learning Algorithms\n(sep-privacy?)\n\n\nAlgorithmic and Human Decision Making: For a Double Standard of Transparency\n(sep-privacy?)\n\n\nThe Right to an Explanation\n(sep-privacy?)\n\n\nThe Mythos of Model Interpretability\n(sep-privacy?)"
  },
  {
    "objectID": "readings/Explainability.html#explainability-transparency-and-interpretability-readings",
    "href": "readings/Explainability.html#explainability-transparency-and-interpretability-readings",
    "title": "Explainability",
    "section": "",
    "text": "Title\nCitation\n\n\n\n\nTransparency in Complex Computational Systems\n(sep-privacy?)\n\n\nHow the Machine “Thinks”: Understanding Opacity in Machine Learning Algorithms\n(sep-privacy?)\n\n\nAlgorithmic and Human Decision Making: For a Double Standard of Transparency\n(sep-privacy?)\n\n\nThe Right to an Explanation\n(sep-privacy?)\n\n\nThe Mythos of Model Interpretability\n(sep-privacy?)"
  },
  {
    "objectID": "readings/Explainability.html#references",
    "href": "readings/Explainability.html#references",
    "title": "Explainability",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "readings/Predictive-Policing.html",
    "href": "readings/Predictive-Policing.html",
    "title": "Predictive Policing",
    "section": "",
    "text": "Title\nCitation"
  },
  {
    "objectID": "readings/Predictive-Policing.html#references",
    "href": "readings/Predictive-Policing.html#references",
    "title": "Predictive Policing",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "readings/Privacy.html",
    "href": "readings/Privacy.html",
    "title": "Privacy",
    "section": "",
    "text": "Title\nCitation\n\n\n\n\nPrivacy (Stanford Encyclopedia of Philosophy)\nDeCew (2018)\n\n\nWhy Privacy is Important\nRachels (1975)\n\n\nWhy We Care about Privacy\nMcFarland (2012)\n\n\nPrivacy and Human Behavior in the Age of Information\nAcquisti, Brandimarte, & Loewenstein (2015)\n\n\nSurveillance and Capture: Two Models of Privacy\nAcquisti et al. (2015)\n\n\nFrom Individual to Group Privacy in Big Data Analytics\nMittelstadt (2017)\n\n\nA Modern Pascal’s Wager for Mass Electronic Surveillance\nDanks (2014)\n\n\nPrivacy and Paternalism: The Ethics of Student Data Collection\nCreel & Dixit (2022)\n\n\nBig Data’s End Run around Procedural Privacy Protections\nBarocas & Nissenbaum (2014)\n\n\nWhy ‘I Have Nothing to Hide’ is the Wrong Way to Think About Surveillance\nBarocas & Nissenbaum (2014)\n\n\nCan a Set of Equations keep U.S. Census Data Private?\nBarocas & Nissenbaum (2014)\n\n\nWhy ‘Anonymous’ Data Sometimes Isn’t\nSchneier (2007)"
  },
  {
    "objectID": "readings/Privacy.html#additional-privacy-readings",
    "href": "readings/Privacy.html#additional-privacy-readings",
    "title": "Privacy",
    "section": "Additional Privacy Readings",
    "text": "Additional Privacy Readings\n\nPhilosophy of Privacy and Digital Life\nNothing to Hide\nIt’s Not Privacy, and It’s Not Fair\nDigital Reputation in an Era of Runaway Data\nThe Surveillance Society\nRecommender Systems and Their Ethical Challenges"
  },
  {
    "objectID": "readings/Privacy.html#references",
    "href": "readings/Privacy.html#references",
    "title": "Privacy",
    "section": "References",
    "text": "References\n\n\nAcquisti, A., Brandimarte, L., & Loewenstein, G. (2015). Privacy and human behavior in the age of information. Science (New York, N.Y.), 347, 509–514. https://doi.org/10.1126/science.aaa1465\n\n\nBarocas, S., & Nissenbaum, H. (2014). Big data’s end run around procedural privacy protections. Communications of the ACM, 57, 31–33. https://doi.org/10.1145/2668897\n\n\nCreel, K., & Dixit, T. (2022). Privacy and Paternalism: The Ethics of Student Data Collection. https://thereader.mitpress.mit.edu/privacy-and-paternalism-the-ethics-of-student-data-collection/; The MIT Press Reader.\n\n\nDanks, D. (2014). A modern pascal’s wager for mass electronic surveillance. https://doi.org/10.1184/R1/6490751.V1\n\n\nDeCew, J. (2018). Privacy. In E. N. Zalta (Ed.), The Stanford encyclopedia of philosophy (Spring 2018). https://plato.stanford.edu/archives/spr2018/entries/privacy/; Metaphysics Research Lab, Stanford University.\n\n\nMcFarland, M. (2012). Why We Care about Privacy. https://www.scu.edu/ethics/focus-areas/internet-ethics/resources/why-we-care-about-privacy/; Markkula Center for Applied Ethics at Santa Clara University.\n\n\nMittelstadt, B. (2017). From individual to group privacy in big data analytics. Philosophy & Technology, 30. https://doi.org/10.1007/s13347-017-0253-7\n\n\nRachels, J. (1975). Why privacy is important. Philosophy & Public Affairs, 4(4), 323–333. Retrieved from http://www.jstor.org/stable/2265077\n\n\nSchneier, B. (2007). Why ’Anonymous’ Data Sometimes Isn’t. https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt/; Wired."
  },
  {
    "objectID": "readings/Responsibility.html",
    "href": "readings/Responsibility.html",
    "title": "Responsibility",
    "section": "",
    "text": "Title\nCitation"
  },
  {
    "objectID": "readings/Responsibility.html#references",
    "href": "readings/Responsibility.html#references",
    "title": "Responsibility",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "readings/Workplace.html",
    "href": "readings/Workplace.html",
    "title": "Workplace",
    "section": "",
    "text": "Title\nCitation"
  },
  {
    "objectID": "readings/Workplace.html#references",
    "href": "readings/Workplace.html#references",
    "title": "Workplace",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "inside-syllabi.html#ethics-in-ai-by-liam-kofi-bright",
    "href": "inside-syllabi.html#ethics-in-ai-by-liam-kofi-bright",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "1.1 Ethics in AI by Liam Kofi Bright",
    "text": "1.1 Ethics in AI by Liam Kofi Bright\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n1.1.1 Background\nThis course was created by Liam Kofi Bright who is a philosopher of science currently at London School of Economics. The course is intended for upper level undergraduate or masters students. There are no formal pre-requisites, though it would be beneficial to have some prior experience with moral/polical philosophy and logic/statistics (Bright, 2022).\n\n\n1.1.2 Course Goals\nThe following is taken from the “Course Intent” section of Bright (2022).\n\nStudents understand what is morally and politically at stake in the wave of automation we are now undergoing.\nStudents grapple with what sort of epistemic capacities we can reasonably expect from AI and other similar algorithms.\nStudents work to understand how the epistemic capacities and moral and political stakes of AI interrelate to one another.\nStudents work to apply philosophical reasoning skills to understand a series of issues surrounding AI that have aroused public concern: stakeholder-transparency, medical uses, labor rights, privacy, AI governance, and aligning AI values with designer values.\n\n\n\n1.1.3 Course Topics\nEach week there is a different central topic. There are primary, secondary, and optional readings listed on the syllabus that relate to the week’s core topic.\nThe core topics are the following:\n\nEthical Foundations I: Bias\nEthical Foundations II: Justice\nExplanatory Desiderata I: Accuracy\nExplanatory Desiderata II: Causal Inference\nthe Good vs the True?\nTransparency\nLabor Rights\nPrivacy\nMedical Decisions\nAI Governance\nAlignment"
  },
  {
    "objectID": "inside-syllabi.html#the-ethics-of-data-and-artificial-intelligence-by-the-london-school-of-economics",
    "href": "inside-syllabi.html#the-ethics-of-data-and-artificial-intelligence-by-the-london-school-of-economics",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "1.2 The Ethics of Data and Artificial Intelligence by the London School of Economics",
    "text": "1.2 The Ethics of Data and Artificial Intelligence by the London School of Economics\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n1.2.1 Background\nThe course is run by the Department of Philosophy, Logic and Scientific Method at the London School of Economics. The lead faculty are all professors within the Department of Philosophy, Logic, and Scientific Method. This course is intended for undergraduates and there are no prerequisites (Kate Vredenburgh, 2023).\n\n\n1.2.2 Course Goals\nThe following is taken from the “Course Outcomes” section of Kate Vredenburgh (2023).\n\nStudents understand core ethics concepts and how those concepts apply to AI systems.\nStudents analyze the ethical issues raised by a particular technology by applying core ethical reasoning techniques to real-world cases.\nStudents apply cutting-edge ethics research within the development process to build more ethical AI systems.\nStudents communicate their own ethical viewpoint clearly and persuasively by reconstructing others’ arguments, objecting to them, and providing their own solution.\n\n\n\n1.2.3 Course Topics\n\nJustice and the control of technology\nWhat is intelligence?\nEvaluating intelligence in AI systems\nParticipatory AI\nData and Privacy\nFair Prediction\nExplainable AI\nAI, Privacy, and Consent to Personal Data Processing on Social Media\nSurveillance and workplace privacy\nAI and value alignment\nAI and democracy: political discourse and social media, regulating power"
  },
  {
    "objectID": "inside-syllabi.html#philosophical-foundations-of-machine-learning-by-carnegie-mellon-university",
    "href": "inside-syllabi.html#philosophical-foundations-of-machine-learning-by-carnegie-mellon-university",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "1.3 Philosophical Foundations of Machine Learning by Carnegie Mellon University",
    "text": "1.3 Philosophical Foundations of Machine Learning by Carnegie Mellon University\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n1.3.1 Background\nThis course is run by Carnegie Mellon’s Machine Learning department. The faculty instructor is Zachary Lipton, who is a professor of Machine Learning and Operations Research. Philosopher Mel Andrews also helps instruct the class. The class is intended for graduate students though undergraduates can enroll with instructor permission. There are no formal prerequisites for the class (Lipton, 2023b).\n\n\n1.3.2 Course Goals\nThere are no explicit/listed course goals on Lipton (2023b). As such, the following list is based on extrapolation from the reading list and course information.\n\nStudents learn the origins of Machine Learning through schlars like Turing, Misnky, and Pearl.\nStudents understand the fundamental problem of induction and the evolution of philosophy of science through scholars like Kuhn, Hacking, and Hofstadter and then apply these philosophical concepts to field of Machine Learning.\nStudents develop a Machine Learning language to talk about the philosophical conceptions related to probability and causal through scholars like Polya, Cox, Cartwright, and Pearl.\nStudents analyze the ethical dimensions of deploying data driven models to automate decisions in consequential domains.\nStudents work to understand Machine Learning algorithms’ relationship to knowledge and creativity.\n\n\n\n1.3.3 Course Topics\nThe course topics are pulled from Lipton (2023a).\n\nThe (Technical) Origins of AI, Cybernetics, and Machine Learning\nThe Problem of Induction\nInduction and Statistical Learning Theory\nCausation\nCategories and Kinds\nEpistemological and Methodological Considerations of Machine Learning\nUnderstanding and Knowledge as it relates to Machine Learning\nGenerative AI, Bullshit, and Creativity\nAI Consciousness\nThe Troubles with Explanation (in Machine Learning)\nEthics I: Justice\nEthics II: Discrimination, Causal Interpretations, and Path-Specific Effects"
  },
  {
    "objectID": "inside-syllabi.html#ethics-data-and-technology-by-the-university-of-florida",
    "href": "inside-syllabi.html#ethics-data-and-technology-by-the-university-of-florida",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "1.4 Ethics, Data, and Technology by the University of Florida",
    "text": "1.4 Ethics, Data, and Technology by the University of Florida\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n1.4.1 Background\nThis course is run by the University of Florida’s Philosophy department. The faculty instructor is David Gray Grant, who is an assistant professor of Philosophy at UF. The class is intended for undergraduates. There are no prerequisites for the class (Grant, 2021).\n\n\n1.4.2 Course Goals\nThe following is taken from the “Course Objectives” section of Grant (2021).\n\nStudents develop of basic vocabulary for discussing the ethical dimensions of data science and its applications.\nStudents analyze the issues and policies concerning emerging “big data” technologies through the application of ethical concepts.\nStudents critique public policies, social practices, and social institutions that shape, and are shaped by, scientific discovery and technology design.\nStudents discern the structure of arguments, represent them fairly and clearly, and evaluate them of cogency.\nStudents formulate original arguments, anticipate objections, and respond in a conscientious fashion\nStudents read and sicuss complex philosophical texts from both historical sources and contemporary works\nStudents speak and write clearly and persuasively about abstract and conceptually elusive matters.\n\n\n\n1.4.3 Course Topics\n\nThe Alignment Problem: Defining ‘Algorithm’ and recognizing the gap between the values embedded into algorithms and our human values.\nIntroduction to Ethics: Consequentialism\nAI Safety\nPrivacy and Surveillance Capitalism (with a case study analysis)\nAutonomy and the Attention Economy (with a case study analysis)\nAlgorithmic Opacity (with a case study analysis)\nAlgorithmic Bias (with a case study analysis)\nResponsibility Gaps"
  },
  {
    "objectID": "inside-syllabi.html#data-ethics-by-the-university-of-california-san-diego",
    "href": "inside-syllabi.html#data-ethics-by-the-university-of-california-san-diego",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "1.5 Data Ethics by the University of California, San Diego",
    "text": "1.5 Data Ethics by the University of California, San Diego\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n1.5.1 Background\nThis course is run by the University of California, San Diego’s Philosophy department. The faculty instructor is David Danks, who is a professor of Data Science and Philosophy. There are no formal prerequisites for this course (Danks, 2023).\n\n\n1.5.2 Course Outcomes\nThese are taken from the “Learning Objectives” section of Danks (2023).\n\nStudents can describe the many ways that ethical issues arise throughout the lifecycle of a data science effort.\nStudents can generate appropriate ethical questions for a given data science effort\nStudents can work individually or collaboratively to develop more ethical & responsible data science projects.\n\n\n\n1.5.3 Course Topics\n\nLifecycle of a data science effort\nRights, values, and interests in data science\nThe neutrality thesis for data and technology\nAlgorithmic society\nPrivacy and Consent in Data Collection and Use\nBias and Fairness in Data Analysis and Modeling\nAlgorithmic Explainability\nAlgorithmic Justice\nAccountability in Using Data\nData Colonialism and Sovereignty\nCase Studies in Workplace Surveillance and Healthcare Resources"
  },
  {
    "objectID": "inside-syllabi.html#ethics-and-technology-by-swarthmore-college",
    "href": "inside-syllabi.html#ethics-and-technology-by-swarthmore-college",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "1.6 Ethics and Technology by Swarthmore College",
    "text": "1.6 Ethics and Technology by Swarthmore College\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n1.6.1 Background\nThis course is run by Swarthmore College. It is a first-year seminar course that is co-taught by Ameet Soni, an Associate Professor of Computer Science, and Krista Karbowski Thomason, an Associate Professor of Philosophy. The course has no formal prerequisites (Soni & Thomason, 2019).\n\n\n1.6.2 Course Outcomes\nThe following is extrapolated from the “Course Goals” sections and course readings listed in Soni & Thomason (2019).\n\nStudents improve their ability to read and write philosophically.\nStudents gain an understanding of some key ethical theories and how they would be applied.\nStudents understand fundamental ethical issues surrounding algorithms such as bias, surveillance and privacy, and consciousness in AI.\nStudents improve their ability to craft a philosophical argument surrounding the ethical issues listed above.\n\n\n\n1.6.3 Course Topics\n\nWriting/Reading like a Philosopher\nApplied Ethical Theory: Relativism, Virtue Ethics, Humean Ethics, Kantian Ethics, Utilitarianism, Feminist Ethics, Buddhist Ethics\nDefinitions of Technology\nMachine Learning and Algorithmic Bias\nSurveillance and Privacy\nEthics surrounding Artificial Intelligence\nTranshumanism"
  },
  {
    "objectID": "inside-syllabi.html#ethics-and-policy-of-data-analytics-by-carnegie-mellon-university",
    "href": "inside-syllabi.html#ethics-and-policy-of-data-analytics-by-carnegie-mellon-university",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "1.7 Ethics and Policy of Data Analytics by Carnegie Mellon University",
    "text": "1.7 Ethics and Policy of Data Analytics by Carnegie Mellon University\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n1.7.1 Background\nThis course is run by Carnegie Mellon University’s Department of Information Systems and Public Policy. The faculty instructors are David Danks, who is a Professor of Data Science and Philosophy, and Sina Fazelpour, who is an Assistant Professor of Philosophy and Computer Science. There are no formal prerequisites for the course, though some familiarity with the data analytics pipeline is helpful (Danks & Fazelpour, 2021).\n\n\n1.7.2 Course Outcomes\nThe following is taken from the “Learning Objectives” section of Danks & Fazelpour (2021).\n\nStudents understand the key concepts of privacy, fairness, bias, explainability, and trust.\nStudents can determine the ethical impacts (along these dimensions) of various standard data analysis practices, methods, and products.\nStudents can derive relevant, key policy and legal constraints on data analytic practices and products.\nStudents can apply both ethical and policy considerations to an analysis of the permissibility and/or legitimacy of different data analytics.\n\n\n\n1.7.3 Course Topics\n\nCharacterizations of the “Ethics and Policy of Data Analytics”\nPrivacy: its Ethical and Policy Considerations in Big Data Analytics\nFairness and Bias: Ethical and Policy Considerations within Algorithmic Fairness Measures\nExplainability: Ethical and Policy Considerations in Algorithms\nTrust: a Unifying Approach?"
  },
  {
    "objectID": "inside-syllabi.html#data-ethics-and-society-by-rice-university",
    "href": "inside-syllabi.html#data-ethics-and-society-by-rice-university",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "1.8 Data, Ethics, and Society by Rice University",
    "text": "1.8 Data, Ethics, and Society by Rice University\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n1.8.1 Background\nThis course is run by Rice University’s Department of Data Science. The faculty instructor is Elizabeth Petrick, who is an Associate Professor of History. The course is meant for undergraduates and has no formal prerequisites (Petrick, 2021).\n\n\n1.8.2 Course Outcomes\nThe following is taken from the “Objectives” section of Petrick (2021).\n\nStudents will be able to explain the history of ethical concerns with data.\nStudents will be able to apply ethical reasoning when gathering, processing, and analyzing data.\nStudents will explore their individual ethical commitments as future data scientists.\n\n\n\n1.8.3 Course Topics\n\nFundamental Ethical Frameworks: Utilitarianism, Deontology (Kantian Ethics), Virtue Ethics.\nWho Counts and Who is Counted in Data Science: includes issues surrounding consent.\nHow is Data Resisted: Issues in Privacy\nWho Owns and Controls Data: Governmental Surveillance, Data Security and Hacking, Data Breaches\nHow is Data Gathered and Used Today: The Right to be Forgotten, Internet Companies, Biometrics, Fingerprinting.\nMachine Learning: Disability and AI, Creation and Circulation of Datasets, Autonomous Vehicles\nAlgorithms and Bias"
  },
  {
    "objectID": "inside-syllabi.html#data-science-ethics-by-yale-university",
    "href": "inside-syllabi.html#data-science-ethics-by-yale-university",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "2.1 Data Science Ethics by Yale University",
    "text": "2.1 Data Science Ethics by Yale University\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n2.1.1 Background\nThis course is run by Yale University’s Department of Statistics and Data Science. The faculty instructor is Elisa Celis, who is an assistant professor of Statistics and Data Science. The class is intended for undergraduates. The formal prerequisites for this class are probability and statistics as well as a data analysis course. Furthermore, prior coursework in AI/ML/Algorithms and Ethics/Philosophy is recommended (Celis, 2019).\n\n\n2.1.2 Course Outcomes\nThe following are taken from the “Course Learning Objectives” section of Celis (2019).\n\nStudents develop fluency in the key technical, ethical, policy, and legal terms and concepts related to data science.\nStudents learn about algorithmic and data-driven approaches for mitigating biases in AI/ML systems.\nStudents reason through problems with no clear answer in a systematic manner, taking and defending different viewpoints, and justifying your conclusions in a rigorous manner.\nStudents improve their writing and communication skills both with a technical and lay audience.\nStudents listen, understand and communicate with people of varying opinions, viewpoints, and ideas.\n\n\n\n2.1.3 Course Topics\n\nData Collection and Representation and Privacy via subtopics such as Data Sampling and Collection, Managing Datasets Responsibility and Data Cannibalism, the Goal(s) of Data Science, Inference and Privacy, and Re-Identification of Data.\nMachine Bias via subtopics such as Characterizing Machine Bias, Bias versus Correlation versus Causation, Understanding Fairness and Discrimination, Trade-offs between Data Science versus and Human Agents.\nSolutions to Bias via Algorithmic Fairness via subtopics such as Preprocessing Approaches and Debiasing Datasets, Impossibility Results, In-Processing Approaches to Fairness, Fairness in Deep Learning, and Representative Fairness.\nSocial Implications and Feedback Loops via subtopics such as Polarization and Feedback Loops, Algorithmic Persuasion, Employment, Advertising, Opportunity, Understanding “Who is” Data Science.\nControlling Machine Learning Systems via subtopics such as Transparency, Explainability/Interpretability, Accountability, Auditing Algorithms."
  },
  {
    "objectID": "inside-syllabi.html#computing-ethics-and-society-by-northwestern-university",
    "href": "inside-syllabi.html#computing-ethics-and-society-by-northwestern-university",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "2.2 Computing, Ethics, and Society by Northwestern University",
    "text": "2.2 Computing, Ethics, and Society by Northwestern University\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n2.2.1 Background\nThis course is run by Northwestern University’s Computer Science Department in the School of Engineering. The course is taught by Sarah Van Wart, an assistant professor of instruction in Computer Science and Engineering. The course has no formal prerequisites (Wart, 2021).\n\n\n2.2.2 Course Outcomes\nThe following is taken from the “Course Learning Goals” section of Wart (2021).\n\nStudents recognize the impact of one’s own assumptions, biases, and experiences.\nStudents identify (and question) dominant/normative ways of thinking about computing and technology.\nStudents understand some of the underlying concepts that power AI and the internet.\nStudents develop a framework for thinking about the relationship between technology and society.\nStudents consider how to participate in a world that is heavily mediated by computing.\n\n\n\n2.2.3 Course Topics\nThese are based on “Schedule” listed on Wart (2021).\n\nMorality, Ethics, and Human Values: Humans’ relationship to morality, understanding fundamental ethical frameworks such as Utilitarianism, Libertarianism, and Kantian ethics.\nTheories of Technology and Society: Understanding the relationship between human values and technology specifically with respect to race and social categories, media representation, surveillance, technological benevolence, and the role of classification systems in perpetuating systematic injustices.\nComputing Infrastructures: Big Data, Surveillance, AI, Content Moderation on Platforms, Business Models of Platforms, and combining these with normative values discussed earlier in the class."
  },
  {
    "objectID": "inside-syllabi.html#special-topics-in-data-science-responsible-data-science-by-new-york-university",
    "href": "inside-syllabi.html#special-topics-in-data-science-responsible-data-science-by-new-york-university",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "2.3 Special Topics in Data Science: Responsible Data Science by New York University",
    "text": "2.3 Special Topics in Data Science: Responsible Data Science by New York University\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n2.3.1 Background\nThis course is run by New York University’s Center for Data Science. It is taught by Julia Stoyanovich, who is an assistant professor of Data Science, Computer Science, and Engineering. The course has formal prerequisites of either Introduction to Data Science or Introduction to Computer Science or similar (Stoyanovich, 2019a).\n\n\n2.3.2 Course Outcomes\nThe following is taken from the “Learning Objectives” section of Stoyanovich (2019b).\n\nStudents can construct an end-to-end case study that illustrates the role of data science in society.\nStudents can explain the ethical and/or legal constraints in the collection and sharing of data according to a framework of the student’s choice.\nStudents can implement a computer program that applies anonymization and privacy techniques to a dataset, and explain the trade-offs with utility.\nStudents can articulate the differences between various interpretations of algorithmic fairness, and relate these interpretations to the points of view of different stakeholders.\nStudents can implement a computer program that audits a black-box classifier.\n\n\n\n2.3.3 Course Topics\n\nAlgorithmic Fairness\nCausality in Algorithms (and its Relationship to Algorithmic Fairness)\nAnonymity and Privacy in Data Science\nThe Trade-off between Privacy and Utility\nProfiling and Particularity\nAlgorithmic Transparency\nData Cleaning\nLegal frameworks, Codes of Ethics, and Personal Responsibility around Data Science\nCivil Rights, Predictive Policing, and Criminal Justice."
  },
  {
    "objectID": "inside-syllabi.html#ethical-and-social-issues-in-ai-by-cornell-university",
    "href": "inside-syllabi.html#ethical-and-social-issues-in-ai-by-cornell-university",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "2.4 Ethical and Social Issues in AI by Cornell University",
    "text": "2.4 Ethical and Social Issues in AI by Cornell University\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n2.4.1 Background\nThis course is run by Cornell University’s Computer Science Department. The faculty instructors are Joseph Halpern and Bart Selman, who are both Professors of Computer Science. The course is meant for undergraduates and there are no formal prerequisites for the course. Additionally, it is worth noting that this course is offered only as a Pass/No Credit discussion; there are no assignments beyond “active participation” in the class discussions (Halpern & Selman, 2017).\n\n\n2.4.2 Course Outcomes\nThe following is extrapolated from the required readings and abstracts listed in Halpern & Selman (2017).\n\nStudents understand some of the key ethical issues that are associated with developing and employing algorithmic technologies.\nStudents foresee some of the potential ethical and social issues facing the development and (widespread) employment of algorithmic technologies.\nStudents develop their ability to use philosophical language/frameworks to approach issues in AI.\nStudents learn how to engage in discussions of the ethical and social issues of AI, where there are various stakeholders to consider.\n\n\n\n2.4.3 Course Topics\nThe following is extrapolated from the required readings and abstracts listed in Halpern & Selman (2017).\n\nFuture of AI: Laying out the Benefits and Risks\nInherent Trade-offs in Algorithmic Fairness\nInterpretable AI\nComputational Ethics for AI\nThe Relationship between Humans and Machines in the Workplace\nThe Ethics of Robotics, Autonomy, Embodiment, and Anthropomorphism\nMoral Responsibility, Blameworthiness, and Intention of AI"
  },
  {
    "objectID": "inside-syllabi.html#ethics-public-policy-and-technological-change-by-stanford-university",
    "href": "inside-syllabi.html#ethics-public-policy-and-technological-change-by-stanford-university",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "3.1 Ethics, Public Policy, and Technological Change by Stanford University",
    "text": "3.1 Ethics, Public Policy, and Technological Change by Stanford University\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n3.1.1 Background\nThis course in run by Stanford University’s Department of Computer Science. The course instructors are Rob Reich (Professor of Political Science), Mehran Sahami (Professor of Computer Science and Engineering), and Jeremy Weinstein (Professor of Political Science). The course is meant for undergraduates and it has no formal prerequisites (Rob Reich & Weinstein, 2023).\n\n\n3.1.2 Course Outcomes\nThe following is extrapolated from the “Course Description” section and required readings of Rob Reich & Weinstein (2023).\n\nStudents integrate perspectives from computer science, philosophy, and social science to robustly and holistically examine the impact of technology on humans and societies.\nStudents critically reflect on their role as enablers and shapers of technological change in society.\nStudents will learn how to engage with students across different disciplines in discussions about the ethical and socio-political dimensions of technologies.\n\n\n\n3.1.3 Course Topics\n\nAlgorithmic Decision-making\nThe Political Economy of Technology\nData Collection, Privacy, and Civil Liberties\nArtificial Intelligence and Autonomous Systems\nPower of Private Platforms\nBlockchain and Decentralized Technical Architectures\n\nEach topic is broken down into 6 sub-modules: Promise and Perils, Technical Deep Dive, Rights and Responsibilities, Moderated Discussion with Experts, Tensions and Trade-offs via a Case Study, and Making Product/System/Policy Choices in Light of these Trade-offs"
  },
  {
    "objectID": "inside-syllabi.html#human-contexts-and-ethics-of-data-by-the-university-of-california-berkeley",
    "href": "inside-syllabi.html#human-contexts-and-ethics-of-data-by-the-university-of-california-berkeley",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "3.2 Human Contexts and Ethics of Data by the University of California, Berkeley",
    "text": "3.2 Human Contexts and Ethics of Data by the University of California, Berkeley\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n3.2.1 Background\nThis course is run by University of California, Berkeley’s College of Computing, Data Science, and Society (and cross-listed by the History and Science Technology and Society department). This course’s faculty instructors are Margo Boenig-Lipstin, who is the Director of Human Context and Ethics, and Ari Edmundson, who is a Lecturer in UC Berkeley’s Data Science Undergraduate Studies Program. The course has no formal prerequisites (Boenig-Lipstin & Edmundson, 2020).\n\n\n3.2.2 Course Outcomes\nThe following is taken from the “Scope and Objectives” section of Boenig-Lipstin & Edmundson (2020).\n\nStudents understand the challenge and importance of doing ethical data science amid shifting definitions of human subjects, consent, and privacy.\nStudents grapple with the changing relationship between data, democracy, and law.\nStudents understand the role of data analytics in how corporations and governments provide public goods such as health and security to citizens.\nStudents explore technologies like sensors, machine learning, and artificial intelligence and how they are changing the landscapes of labor, industry, and city life.\nStudents reflect on the implications of data for how the public and varied scientific disciplines know the world.\n\n\n\n3.2.3 Course Topics\n\nThe History of Datafication\nData Futures: Past and Present\nCharacterizations of Data and Data Science\n(Ethically) Responsible Data Science\nData Shaping Identities\nPopulations and States\nSurveillance and Security\nPredictive Policing\nMaking Arguments with Data\nChoice, Influence, Manipulation, and Governance\nAlgorithmic Sentencing\nData and Democracy\nData’s Influence on Scientific Research\nMachines and Industry\nThe Ethos of Making"
  },
  {
    "objectID": "inside-syllabi.html#the-ethics-and-governance-of-artificial-intelligence-by-the-massachusetts-institute-of-technology",
    "href": "inside-syllabi.html#the-ethics-and-governance-of-artificial-intelligence-by-the-massachusetts-institute-of-technology",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "3.3 The Ethics and Governance of Artificial Intelligence by the Massachusetts Institute of Technology",
    "text": "3.3 The Ethics and Governance of Artificial Intelligence by the Massachusetts Institute of Technology\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n3.3.1 Background\nThis course is a Cross-Disciplinary course run by the Massachusetts Institute of Technology. The faculty instructors are Joi Ito, who is a Professor of Practice in Media Arts and Science, and Jonathan Zittrain, who is a Professor of International Law, Computer Science, and Public Policy. The course is meant for graduate students and there are no formal prerequisites (Ito & Zittrain, 2018).\n\n\n3.3.2 Course Outcomes\nThe following is extrapolated from the “Course Description” section and course readings listed on Ito & Zittrain (2018).\n\nStudents investigate the implications of emerging technologies (with an emphasis on the development and deployment of AI) from a cross-disciplinary perspective.\nStudents grapple with complex issues surrounding AI such as how to balance regulation and innovation, how AI influences the dissemination of information, and questions related to individual rights.\nStudents analyze socio-political perspectives related to AI case studies in private corporations, labor, and governance.\n\n\n\n3.3.3 Course Topics\n\nMachine Learning and Philosophy of Mind\nAlgorithmic Opacity\nAutonomy, System Design, Agency, and Liability\nAlgorithmic Bias: with case studies in Risk Assessment, Predictive Policing, Credit Scoring, and Image Recognition\nOwnership, Control, and Access\nGovernance, Explainability, Accountability\nLabor, Automation, and Regulation\nEthics, Morals, and Frontiers"
  },
  {
    "objectID": "inside-syllabi.html#ethics-and-policy-in-data-science-by-cornell-university",
    "href": "inside-syllabi.html#ethics-and-policy-in-data-science-by-cornell-university",
    "title": "Inside the Data Science Ethics Syllabi",
    "section": "3.4 Ethics and Policy in Data Science by Cornell University",
    "text": "3.4 Ethics and Policy in Data Science by Cornell University\n\n\n\n\n\n\nCourse Information\n\n\n\n\n\n\n3.4.1 Background\nThis course is run by Cornell University’s Department of Information Science. The faculty instructor for the course in Solon Barocas, who is an Adjunct Assistant Professor in the Department of Information Science and Principal Researcher at Microsoft. The course is meant for Masters/Undergraduate students and has no formal prerequisites (Barocas, 2017).\n\n\n3.4.2 Course Outcomes\nThe following is extrapolated from the “Course Description and Objectives” section of Barocas (2017).\n\nStudents can recognize where and understand why ethical issues and policy questions can arise when applying data science to real world problems.\nStudents develop fluency in key technical, ethical, policy, and legal terms and concepts that are relevant to a normative assessment of data science and gain exposure to legal scholarship and policy documents that will help them understand the current regulatory environment and potential future environments.\nStudents develop their ability to bring analytic and technical precision to normative debates about the role that data science, machine learning, and artificial intelligence play in consequential decision-making in commerce, employment, finance, healthcare, education, policing, and other areas.\nStudents will develop tools to conceptualize, measure, and mitigate bias in data-driven decision-making, to audit and evaluate models, and render these analytic tools more interpretable and their determinations more explainable.\n\n\n\n3.4.3 Course Topics\n\nCharacterizing Data and the Importance of Data Science Ethics\nAlgorithmic Bias and Exclusion\nThe Social Science of Discrimination\nHow Machines Learn to Discriminate\nAuditing Algorithms\nFormalizing and Enforcing Fairness in Machine Learning\nProfiling and Particularity\nAllocative to Representational Harms\nTransparency and Due Process\nInterpretability in Machine Learning\nThe Value of Explanation\nPrivacy\nPrice Discrimination\nCase Studies with Insurance\nAlgorithmic Persuasion and Manipulation\nCase Studies with Hiring"
  },
  {
    "objectID": "syllabi-table-code.html",
    "href": "syllabi-table-code.html",
    "title": "Syllabi Table Creation",
    "section": "",
    "text": "html file saved to /Users/sara/Desktop/data-science-ethics/syllabi-table.html"
  },
  {
    "objectID": "Intro-DS-ethics.html",
    "href": "Intro-DS-ethics.html",
    "title": "What is Data Science Ethics?",
    "section": "",
    "text": "Comic via Evil AI Cartoons."
  },
  {
    "objectID": "Intro-DS-ethics.html#footnotes",
    "href": "Intro-DS-ethics.html#footnotes",
    "title": "What is Data Science Ethics?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt is also worth noting that some philosophers just focus on what we should do in specific cases and do not appeal to overarching ethical theories at all↩︎"
  }
]