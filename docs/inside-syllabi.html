<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Data Science Ethics – Inside the Data Science Ethics Syllabi</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./images/favicon.ico" rel="icon">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/iconify-2.1.0/iconify-icon.min.js"></script>
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": "tree",
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./images/favicon.ico" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Data Science Ethics</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-intro-to-data-science-ethics" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Intro to Data Science Ethics</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-intro-to-data-science-ethics">    
        <li>
    <a class="dropdown-item" href="./Intro-DS-ethics.html">
 <span class="dropdown-text">What is Data Science Ethics?</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Intro-DS-lifecycle.html">
 <span class="dropdown-text">The Data Science Lifecycle</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-inside-the-syllabi" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Inside the Syllabi</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-inside-the-syllabi">    
        <li>
    <a class="dropdown-item" href="./inside-syllabi.html">
 <span class="dropdown-text">Data Science Ethics Syllabi</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Common-Topics.html">
 <span class="dropdown-text">Most Common Syllabi Topics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./DS-pipeline.html">
 <span class="dropdown-text">Data Science Lifecycle Connections</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="./Reading-Tags.html"> 
<span class="menu-text">Reading Lists</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="1">
    <h2 id="toc-title">Page Contents</h2>
   
  <ul>
  <li><a href="#philosophy-oriented-courses" id="toc-philosophy-oriented-courses" class="nav-link active" data-scroll-target="#philosophy-oriented-courses"><span class="header-section-number">1</span> Philosophy-Oriented Courses</a>
  <ul class="collapse">
  <li><a href="#ethics-in-ai-by-liam-kofi-bright" id="toc-ethics-in-ai-by-liam-kofi-bright" class="nav-link" data-scroll-target="#ethics-in-ai-by-liam-kofi-bright"><span class="header-section-number">1.1</span> Ethics in AI by Liam Kofi Bright</a></li>
  <li><a href="#the-ethics-of-data-and-artificial-intelligence-by-the-london-school-of-economics" id="toc-the-ethics-of-data-and-artificial-intelligence-by-the-london-school-of-economics" class="nav-link" data-scroll-target="#the-ethics-of-data-and-artificial-intelligence-by-the-london-school-of-economics"><span class="header-section-number">1.2</span> The Ethics of Data and Artificial Intelligence by the London School of Economics</a></li>
  <li><a href="#philosophical-foundations-of-machine-learning-by-carnegie-mellon-university" id="toc-philosophical-foundations-of-machine-learning-by-carnegie-mellon-university" class="nav-link" data-scroll-target="#philosophical-foundations-of-machine-learning-by-carnegie-mellon-university"><span class="header-section-number">1.3</span> Philosophical Foundations of Machine Learning by Carnegie Mellon University</a></li>
  <li><a href="#ethics-data-and-technology-by-the-university-of-florida" id="toc-ethics-data-and-technology-by-the-university-of-florida" class="nav-link" data-scroll-target="#ethics-data-and-technology-by-the-university-of-florida"><span class="header-section-number">1.4</span> Ethics, Data, and Technology by the University of Florida</a></li>
  <li><a href="#data-ethics-by-the-university-of-california-san-diego" id="toc-data-ethics-by-the-university-of-california-san-diego" class="nav-link" data-scroll-target="#data-ethics-by-the-university-of-california-san-diego"><span class="header-section-number">1.5</span> Data Ethics by the University of California, San Diego</a></li>
  <li><a href="#ethics-and-technology-by-swarthmore-college" id="toc-ethics-and-technology-by-swarthmore-college" class="nav-link" data-scroll-target="#ethics-and-technology-by-swarthmore-college"><span class="header-section-number">1.6</span> Ethics and Technology by Swarthmore College</a></li>
  <li><a href="#ethics-and-policy-of-data-analytics-by-carnegie-mellon-university" id="toc-ethics-and-policy-of-data-analytics-by-carnegie-mellon-university" class="nav-link" data-scroll-target="#ethics-and-policy-of-data-analytics-by-carnegie-mellon-university"><span class="header-section-number">1.7</span> Ethics and Policy of Data Analytics by Carnegie Mellon University</a></li>
  <li><a href="#data-ethics-and-society-by-rice-university" id="toc-data-ethics-and-society-by-rice-university" class="nav-link" data-scroll-target="#data-ethics-and-society-by-rice-university"><span class="header-section-number">1.8</span> Data, Ethics, and Society by Rice University</a></li>
  </ul></li>
  <li><a href="#data-science-oriented-courses" id="toc-data-science-oriented-courses" class="nav-link" data-scroll-target="#data-science-oriented-courses"><span class="header-section-number">2</span> Data Science-Oriented Courses</a>
  <ul class="collapse">
  <li><a href="#data-science-ethics-by-yale-university" id="toc-data-science-ethics-by-yale-university" class="nav-link" data-scroll-target="#data-science-ethics-by-yale-university"><span class="header-section-number">2.1</span> Data Science Ethics by Yale University</a></li>
  <li><a href="#computing-ethics-and-society-by-northwestern-university" id="toc-computing-ethics-and-society-by-northwestern-university" class="nav-link" data-scroll-target="#computing-ethics-and-society-by-northwestern-university"><span class="header-section-number">2.2</span> Computing, Ethics, and Society by Northwestern University</a></li>
  <li><a href="#special-topics-in-data-science-responsible-data-science-by-new-york-university" id="toc-special-topics-in-data-science-responsible-data-science-by-new-york-university" class="nav-link" data-scroll-target="#special-topics-in-data-science-responsible-data-science-by-new-york-university"><span class="header-section-number">2.3</span> Special Topics in Data Science: Responsible Data Science by New York University</a></li>
  <li><a href="#ethical-and-social-issues-in-ai-by-cornell-university" id="toc-ethical-and-social-issues-in-ai-by-cornell-university" class="nav-link" data-scroll-target="#ethical-and-social-issues-in-ai-by-cornell-university"><span class="header-section-number">2.4</span> Ethical and Social Issues in AI by Cornell University</a></li>
  </ul></li>
  <li><a href="#miscellaneous-courses" id="toc-miscellaneous-courses" class="nav-link" data-scroll-target="#miscellaneous-courses"><span class="header-section-number">3</span> Miscellaneous Courses</a>
  <ul class="collapse">
  <li><a href="#ethics-public-policy-and-technological-change-by-stanford-university" id="toc-ethics-public-policy-and-technological-change-by-stanford-university" class="nav-link" data-scroll-target="#ethics-public-policy-and-technological-change-by-stanford-university"><span class="header-section-number">3.1</span> Ethics, Public Policy, and Technological Change by Stanford University</a></li>
  <li><a href="#human-contexts-and-ethics-of-data-by-the-university-of-california-berkeley" id="toc-human-contexts-and-ethics-of-data-by-the-university-of-california-berkeley" class="nav-link" data-scroll-target="#human-contexts-and-ethics-of-data-by-the-university-of-california-berkeley"><span class="header-section-number">3.2</span> Human Contexts and Ethics of Data by the University of California, Berkeley</a></li>
  <li><a href="#the-ethics-and-governance-of-artificial-intelligence-by-the-massachusetts-institute-of-technology" id="toc-the-ethics-and-governance-of-artificial-intelligence-by-the-massachusetts-institute-of-technology" class="nav-link" data-scroll-target="#the-ethics-and-governance-of-artificial-intelligence-by-the-massachusetts-institute-of-technology"><span class="header-section-number">3.3</span> The Ethics and Governance of Artificial Intelligence by the Massachusetts Institute of Technology</a></li>
  <li><a href="#ethics-and-policy-in-data-science-by-cornell-university" id="toc-ethics-and-policy-in-data-science-by-cornell-university" class="nav-link" data-scroll-target="#ethics-and-policy-in-data-science-by-cornell-university"><span class="header-section-number">3.4</span> Ethics and Policy in Data Science by Cornell University</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Inside the Data Science Ethics Syllabi</h1>
<p class="subtitle lead">includes each course’s listed background information, outcomes, and topics</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<hr>
<section id="philosophy-oriented-courses" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Philosophy-Oriented Courses</h1>
<p>These are the courses that we categorize as philosophy-oriented data science ethics courses as the reading lists and/or assignments that students in the course are expected to produce align more with a philosophy course.</p>
<section id="ethics-in-ai-by-liam-kofi-bright" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="ethics-in-ai-by-liam-kofi-bright"><span class="header-section-number">1.1</span> Ethics in AI by Liam Kofi Bright</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="background"><span class="header-section-number">1.1.1</span> Background</h3>
<p>This course was created by Liam Kofi Bright who is a philosopher of science currently at London School of Economics. The course is intended for upper level undergraduate or masters students. There are no formal pre-requisites, though it would be beneficial to have some prior experience with moral/polical philosophy and logic/statistics <span class="citation" data-cites="Liam-Kofi-syllabus">(<a href="#ref-Liam-Kofi-syllabus" role="doc-biblioref">Bright, 2022</a>)</span>.</p>
</section>
<section id="course-goals" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="course-goals"><span class="header-section-number">1.1.2</span> Course Goals</h3>
<p>The following is taken from the “Course Intent” section of <span class="citation" data-cites="Liam-Kofi-syllabus">Bright (<a href="#ref-Liam-Kofi-syllabus" role="doc-biblioref">2022</a>)</span>.</p>
<ul>
<li><p>Students understand what is morally and politically at stake in the wave of automation we are now undergoing.</p></li>
<li><p>Students grapple with what sort of epistemic capacities we can reasonably expect from AI and other similar algorithms.</p></li>
<li><p>Students work to understand how the epistemic capacities and moral and political stakes of AI interrelate to one another.</p></li>
<li><p>Students work to apply philosophical reasoning skills to understand a series of issues surrounding AI that have aroused public concern: stakeholder-transparency, medical uses, labor rights, privacy, AI governance, and aligning AI values with designer values.</p></li>
</ul>
</section>
<section id="course-topics" class="level3" data-number="1.1.3">
<h3 data-number="1.1.3" class="anchored" data-anchor-id="course-topics"><span class="header-section-number">1.1.3</span> Course Topics</h3>
<p>Each week there is a different central topic. There are primary, secondary, and optional readings listed on the syllabus that relate to the week’s core topic.</p>
<p>The core topics are the following:</p>
<ul>
<li><p>Ethical Foundations I: Bias</p></li>
<li><p>Ethical Foundations II: Justice</p></li>
<li><p>Explanatory Desiderata I: Accuracy</p></li>
<li><p>Explanatory Desiderata II: Causal Inference</p></li>
<li><p>the Good vs the True?</p></li>
<li><p>Transparency</p></li>
<li><p>Labor Rights</p></li>
<li><p>Privacy</p></li>
<li><p>Medical Decisions</p></li>
<li><p>AI Governance</p></li>
<li><p>Alignment</p></li>
</ul>
</section>
</div>
</div>
</div>
<hr>
</section>
<section id="the-ethics-of-data-and-artificial-intelligence-by-the-london-school-of-economics" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="the-ethics-of-data-and-artificial-intelligence-by-the-london-school-of-economics"><span class="header-section-number">1.2</span> The Ethics of Data and Artificial Intelligence by the London School of Economics</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background-1" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="background-1"><span class="header-section-number">1.2.1</span> Background</h3>
<p>The course is run by the Department of Philosophy, Logic and Scientific Method at the London School of Economics. The lead faculty are all professors within the Department of Philosophy, Logic, and Scientific Method. This course is intended for undergraduates and there are no prerequisites <span class="citation" data-cites="LSE-syllabus">(<a href="#ref-LSE-syllabus" role="doc-biblioref">Vredenburgh, Boyle, Voorhoeve, &amp; Romero, 2023</a>)</span>.</p>
</section>
<section id="course-goals-1" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="course-goals-1"><span class="header-section-number">1.2.2</span> Course Goals</h3>
<p>The following is taken from the “Course Outcomes” section of <span class="citation" data-cites="LSE-syllabus">Vredenburgh et al. (<a href="#ref-LSE-syllabus" role="doc-biblioref">2023</a>)</span>.</p>
<ul>
<li><p>Students understand core ethics concepts and how those concepts apply to AI systems.</p></li>
<li><p>Students analyze the ethical issues raised by a particular technology by applying core ethical reasoning techniques to real-world cases.</p></li>
<li><p>Students apply cutting-edge ethics research within the development process to build more ethical AI systems.</p></li>
<li><p>Students communicate their own ethical viewpoint clearly and persuasively by reconstructing others’ arguments, objecting to them, and providing their own solution.</p></li>
</ul>
</section>
<section id="course-topics-1" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="course-topics-1"><span class="header-section-number">1.2.3</span> Course Topics</h3>
<ul>
<li><p>Justice and the control of technology</p></li>
<li><p>What is intelligence?</p></li>
<li><p>Evaluating intelligence in AI systems</p></li>
<li><p>Participatory AI</p></li>
<li><p>Data and Privacy</p></li>
<li><p>Fair Prediction</p></li>
<li><p>Explainable AI</p></li>
<li><p>AI, Privacy, and Consent to Personal Data Processing on Social Media</p></li>
<li><p>Surveillance and workplace privacy</p></li>
<li><p>AI and value alignment</p></li>
<li><p>AI and democracy: political discourse and social media, regulating power</p></li>
</ul>
</section>
</div>
</div>
</div>
<hr>
</section>
<section id="philosophical-foundations-of-machine-learning-by-carnegie-mellon-university" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="philosophical-foundations-of-machine-learning-by-carnegie-mellon-university"><span class="header-section-number">1.3</span> Philosophical Foundations of Machine Learning by Carnegie Mellon University</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background-2" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="background-2"><span class="header-section-number">1.3.1</span> Background</h3>
<p>This course is run by Carnegie Mellon’s Machine Learning department. The faculty instructor is Zachary Lipton, who is a professor of Machine Learning and Operations Research. Philosopher Mel Andrews also helps instruct the class. The class is intended for graduate students though undergraduates can enroll with instructor permission. There are no formal prerequisites for the class <span class="citation" data-cites="CMU-ML-syllabus">(<a href="#ref-CMU-ML-syllabus" role="doc-biblioref">Lipton, 2023b</a>)</span>.</p>
</section>
<section id="course-goals-2" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="course-goals-2"><span class="header-section-number">1.3.2</span> Course Goals</h3>
<p>There are no explicit/listed course goals on <span class="citation" data-cites="CMU-ML-syllabus">Lipton (<a href="#ref-CMU-ML-syllabus" role="doc-biblioref">2023b</a>)</span>. As such, the following list is based on extrapolation from the reading list and course information.</p>
<ul>
<li><p>Students learn the origins of Machine Learning through schlars like Turing, Misnky, and Pearl.</p></li>
<li><p>Students understand the fundamental problem of induction and the evolution of philosophy of science through scholars like Kuhn, Hacking, and Hofstadter and then apply these philosophical concepts to field of Machine Learning.</p></li>
<li><p>Students develop a Machine Learning language to talk about the philosophical conceptions related to probability and causal through scholars like Polya, Cox, Cartwright, and Pearl.</p></li>
<li><p>Students analyze the ethical dimensions of deploying data driven models to automate decisions in consequential domains.</p></li>
<li><p>Students work to understand Machine Learning algorithms’ relationship to knowledge and creativity.</p></li>
</ul>
</section>
<section id="course-topics-2" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="course-topics-2"><span class="header-section-number">1.3.3</span> Course Topics</h3>
<p>The course topics are pulled from <span class="citation" data-cites="CMU-ML-reading">Lipton (<a href="#ref-CMU-ML-reading" role="doc-biblioref">2023a</a>)</span>.</p>
<ul>
<li><p>The (Technical) Origins of AI, Cybernetics, and Machine Learning</p></li>
<li><p>The Problem of Induction</p></li>
<li><p>Induction and Statistical Learning Theory</p></li>
<li><p>Causation</p></li>
<li><p>Categories and Kinds</p></li>
<li><p>Epistemological and Methodological Considerations of Machine Learning</p></li>
<li><p>Understanding and Knowledge as it relates to Machine Learning</p></li>
<li><p>Generative AI, Bullshit, and Creativity</p></li>
<li><p>AI Consciousness</p></li>
<li><p>The Troubles with Explanation (in Machine Learning)</p></li>
<li><p>Ethics I: Justice</p></li>
<li><p>Ethics II: Discrimination, Causal Interpretations, and Path-Specific Effects</p></li>
</ul>
</section>
</div>
</div>
</div>
<hr>
</section>
<section id="ethics-data-and-technology-by-the-university-of-florida" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="ethics-data-and-technology-by-the-university-of-florida"><span class="header-section-number">1.4</span> Ethics, Data, and Technology by the University of Florida</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background-3" class="level3" data-number="1.4.1">
<h3 data-number="1.4.1" class="anchored" data-anchor-id="background-3"><span class="header-section-number">1.4.1</span> Background</h3>
<p>This course is run by the University of Florida’s Philosophy department. The faculty instructor is David Gray Grant, who is an assistant professor of Philosophy at UF. The class is intended for undergraduates. There are no prerequisites for the class <span class="citation" data-cites="UF-syllabus">(<a href="#ref-UF-syllabus" role="doc-biblioref">Grant, 2021</a>)</span>.</p>
</section>
<section id="course-goals-3" class="level3" data-number="1.4.2">
<h3 data-number="1.4.2" class="anchored" data-anchor-id="course-goals-3"><span class="header-section-number">1.4.2</span> Course Goals</h3>
<p>The following is taken from the “Course Objectives” section of <span class="citation" data-cites="UF-syllabus">Grant (<a href="#ref-UF-syllabus" role="doc-biblioref">2021</a>)</span>.</p>
<ul>
<li><p>Students develop of basic vocabulary for discussing the ethical dimensions of data science and its applications.</p></li>
<li><p>Students analyze the issues and policies concerning emerging “big data” technologies through the application of ethical concepts.</p></li>
<li><p>Students critique public policies, social practices, and social institutions that shape, and are shaped by, scientific discovery and technology design.</p></li>
<li><p>Students discern the structure of arguments, represent them fairly and clearly, and evaluate them of cogency.</p></li>
<li><p>Students formulate original arguments, anticipate objections, and respond in a conscientious fashion</p></li>
<li><p>Students read and sicuss complex philosophical texts from both historical sources and contemporary works</p></li>
<li><p>Students speak and write clearly and persuasively about abstract and conceptually elusive matters.</p></li>
</ul>
</section>
<section id="course-topics-3" class="level3" data-number="1.4.3">
<h3 data-number="1.4.3" class="anchored" data-anchor-id="course-topics-3"><span class="header-section-number">1.4.3</span> Course Topics</h3>
<ul>
<li><p>The Alignment Problem: Defining ‘Algorithm’ and recognizing the gap between the values embedded into algorithms and our human values.</p></li>
<li><p>Introduction to Ethics: Consequentialism</p></li>
<li><p>AI Safety</p></li>
<li><p>Privacy and Surveillance Capitalism (with a case study analysis)</p></li>
<li><p>Autonomy and the Attention Economy (with a case study analysis)</p></li>
<li><p>Algorithmic Opacity (with a case study analysis)</p></li>
<li><p>Algorithmic Bias (with a case study analysis)</p></li>
<li><p>Responsibility Gaps</p></li>
</ul>
</section>
</div>
</div>
</div>
<hr>
</section>
<section id="data-ethics-by-the-university-of-california-san-diego" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="data-ethics-by-the-university-of-california-san-diego"><span class="header-section-number">1.5</span> Data Ethics by the University of California, San Diego</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background-4" class="level3" data-number="1.5.1">
<h3 data-number="1.5.1" class="anchored" data-anchor-id="background-4"><span class="header-section-number">1.5.1</span> Background</h3>
<p>This course is run by the University of California, San Diego’s Philosophy department. The faculty instructor is David Danks, who is a professor of Data Science and Philosophy. There are no formal prerequisites for this course <span class="citation" data-cites="UCSD-DataEthics">(<a href="#ref-UCSD-DataEthics" role="doc-biblioref">Danks, 2023</a>)</span>.</p>
</section>
<section id="course-outcomes" class="level3" data-number="1.5.2">
<h3 data-number="1.5.2" class="anchored" data-anchor-id="course-outcomes"><span class="header-section-number">1.5.2</span> Course Outcomes</h3>
<p>These are taken from the “Learning Objectives” section of <span class="citation" data-cites="UCSD-DataEthics">Danks (<a href="#ref-UCSD-DataEthics" role="doc-biblioref">2023</a>)</span>.</p>
<ul>
<li><p>Students can describe the many ways that ethical issues arise throughout the lifecycle of a data science effort.</p></li>
<li><p>Students can generate appropriate ethical questions for a given data science effort</p></li>
<li><p>Students can work individually or collaboratively to develop more ethical &amp; responsible data science projects.</p></li>
</ul>
</section>
<section id="course-topics-4" class="level3" data-number="1.5.3">
<h3 data-number="1.5.3" class="anchored" data-anchor-id="course-topics-4"><span class="header-section-number">1.5.3</span> Course Topics</h3>
<ul>
<li><p>Lifecycle of a data science effort</p></li>
<li><p>Rights, values, and interests in data science</p></li>
<li><p>The neutrality thesis for data and technology</p></li>
<li><p>Algorithmic society</p></li>
<li><p>Privacy and Consent in Data Collection and Use</p></li>
<li><p>Bias and Fairness in Data Analysis and Modeling</p></li>
<li><p>Algorithmic Explainability</p></li>
<li><p>Algorithmic Justice</p></li>
<li><p>Accountability in Using Data</p></li>
<li><p>Data Colonialism and Sovereignty</p></li>
<li><p>Case Studies in Workplace Surveillance and Healthcare Resources</p></li>
</ul>
</section>
</div>
</div>
</div>
<hr>
</section>
<section id="ethics-and-technology-by-swarthmore-college" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="ethics-and-technology-by-swarthmore-college"><span class="header-section-number">1.6</span> Ethics and Technology by Swarthmore College</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background-5" class="level3" data-number="1.6.1">
<h3 data-number="1.6.1" class="anchored" data-anchor-id="background-5"><span class="header-section-number">1.6.1</span> Background</h3>
<p>This course is run by Swarthmore College. It is a first-year seminar course that is co-taught by Ameet Soni, an Associate Professor of Computer Science, and Krista Karbowski Thomason, an Associate Professor of Philosophy. The course has no formal prerequisites <span class="citation" data-cites="Swarthmore-Syllabus">(<a href="#ref-Swarthmore-Syllabus" role="doc-biblioref">Soni &amp; Thomason, 2019</a>)</span>.</p>
</section>
<section id="course-outcomes-1" class="level3" data-number="1.6.2">
<h3 data-number="1.6.2" class="anchored" data-anchor-id="course-outcomes-1"><span class="header-section-number">1.6.2</span> Course Outcomes</h3>
<p>The following is extrapolated from the “Course Goals” sections and course readings listed in <span class="citation" data-cites="Swarthmore-Syllabus">Soni &amp; Thomason (<a href="#ref-Swarthmore-Syllabus" role="doc-biblioref">2019</a>)</span>.</p>
<ul>
<li><p>Students improve their ability to read and write philosophically.</p></li>
<li><p>Students gain an understanding of some key ethical theories and how they would be applied.</p></li>
<li><p>Students understand fundamental ethical issues surrounding algorithms such as bias, surveillance and privacy, and consciousness in AI.</p></li>
<li><p>Students improve their ability to craft a philosophical argument surrounding the ethical issues listed above.</p></li>
</ul>
</section>
<section id="course-topics-5" class="level3" data-number="1.6.3">
<h3 data-number="1.6.3" class="anchored" data-anchor-id="course-topics-5"><span class="header-section-number">1.6.3</span> Course Topics</h3>
<ul>
<li><p>Writing/Reading like a Philosopher</p></li>
<li><p>Applied Ethical Theory: Relativism, Virtue Ethics, Humean Ethics, Kantian Ethics, Utilitarianism, Feminist Ethics, Buddhist Ethics</p></li>
<li><p>Definitions of Technology</p></li>
<li><p>Machine Learning and Algorithmic Bias</p></li>
<li><p>Surveillance and Privacy</p></li>
<li><p>Ethics surrounding Artificial Intelligence</p></li>
<li><p>Transhumanism</p></li>
</ul>
</section>
</div>
</div>
</div>
<hr>
</section>
<section id="ethics-and-policy-of-data-analytics-by-carnegie-mellon-university" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="ethics-and-policy-of-data-analytics-by-carnegie-mellon-university"><span class="header-section-number">1.7</span> Ethics and Policy of Data Analytics by Carnegie Mellon University</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background-6" class="level3" data-number="1.7.1">
<h3 data-number="1.7.1" class="anchored" data-anchor-id="background-6"><span class="header-section-number">1.7.1</span> Background</h3>
<p>This course is run by Carnegie Mellon University’s Department of Information Systems and Public Policy. The faculty instructors are David Danks, who is a Professor of Data Science and Philosophy, and Sina Fazelpour, who is an Assistant Professor of Philosophy and Computer Science. There are no formal prerequisites for the course, though some familiarity with the data analytics pipeline is helpful <span class="citation" data-cites="CMU-DataAnalytics">(<a href="#ref-CMU-DataAnalytics" role="doc-biblioref">Danks &amp; Fazelpour, 2021</a>)</span>.</p>
</section>
<section id="course-outcomes-2" class="level3" data-number="1.7.2">
<h3 data-number="1.7.2" class="anchored" data-anchor-id="course-outcomes-2"><span class="header-section-number">1.7.2</span> Course Outcomes</h3>
<p>The following is taken from the “Learning Objectives” section of <span class="citation" data-cites="CMU-DataAnalytics">Danks &amp; Fazelpour (<a href="#ref-CMU-DataAnalytics" role="doc-biblioref">2021</a>)</span>.</p>
<ul>
<li><p>Students understand the key concepts of privacy, fairness, bias, explainability, and trust.</p></li>
<li><p>Students can determine the ethical impacts (along these dimensions) of various standard data analysis practices, methods, and products.</p></li>
<li><p>Students can derive relevant, key policy and legal constraints on data analytic practices and products.</p></li>
<li><p>Students can apply both ethical and policy considerations to an analysis of the permissibility and/or legitimacy of different data analytics.</p></li>
</ul>
</section>
<section id="course-topics-6" class="level3" data-number="1.7.3">
<h3 data-number="1.7.3" class="anchored" data-anchor-id="course-topics-6"><span class="header-section-number">1.7.3</span> Course Topics</h3>
<ul>
<li><p>Characterizations of the “Ethics and Policy of Data Analytics”</p></li>
<li><p>Privacy: its Ethical and Policy Considerations in Big Data Analytics</p></li>
<li><p>Fairness and Bias: Ethical and Policy Considerations within Algorithmic Fairness Measures</p></li>
<li><p>Explainability: Ethical and Policy Considerations in Algorithms</p></li>
<li><p>Trust: a Unifying Approach?</p></li>
</ul>
</section>
</div>
</div>
</div>
<hr>
</section>
<section id="data-ethics-and-society-by-rice-university" class="level2" data-number="1.8">
<h2 data-number="1.8" class="anchored" data-anchor-id="data-ethics-and-society-by-rice-university"><span class="header-section-number">1.8</span> Data, Ethics, and Society by Rice University</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background-7" class="level3" data-number="1.8.1">
<h3 data-number="1.8.1" class="anchored" data-anchor-id="background-7"><span class="header-section-number">1.8.1</span> Background</h3>
<p>This course is run by Rice University’s Department of Data Science. The faculty instructor is Elizabeth Petrick, who is an Associate Professor of History. The course is meant for undergraduates and has no formal prerequisites <span class="citation" data-cites="Rice-Syllabus">(<a href="#ref-Rice-Syllabus" role="doc-biblioref">Petrick, 2021</a>)</span>.</p>
</section>
<section id="course-outcomes-3" class="level3" data-number="1.8.2">
<h3 data-number="1.8.2" class="anchored" data-anchor-id="course-outcomes-3"><span class="header-section-number">1.8.2</span> Course Outcomes</h3>
<p>The following is taken from the “Objectives” section of <span class="citation" data-cites="Rice-Syllabus">Petrick (<a href="#ref-Rice-Syllabus" role="doc-biblioref">2021</a>)</span>.</p>
<ul>
<li><p>Students will be able to explain the history of ethical concerns with data.</p></li>
<li><p>Students will be able to apply ethical reasoning when gathering, processing, and analyzing data.</p></li>
<li><p>Students will explore their individual ethical commitments as future data scientists.</p></li>
</ul>
</section>
<section id="course-topics-7" class="level3" data-number="1.8.3">
<h3 data-number="1.8.3" class="anchored" data-anchor-id="course-topics-7"><span class="header-section-number">1.8.3</span> Course Topics</h3>
<ul>
<li><p>Fundamental Ethical Frameworks: Utilitarianism, Deontology (Kantian Ethics), Virtue Ethics.</p></li>
<li><p>Who Counts and Who is Counted in Data Science: includes issues surrounding consent.</p></li>
<li><p>How is Data Resisted: Issues in Privacy</p></li>
<li><p>Who Owns and Controls Data: Governmental Surveillance, Data Security and Hacking, Data Breaches</p></li>
<li><p>How is Data Gathered and Used Today: The Right to be Forgotten, Internet Companies, Biometrics, Fingerprinting.</p></li>
<li><p>Machine Learning: Disability and AI, Creation and Circulation of Datasets, Autonomous Vehicles</p></li>
<li><p>Algorithms and Bias</p></li>
</ul>
</section>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="data-science-oriented-courses" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Data Science-Oriented Courses</h1>
<p>These are the courses that we would categorize as data science-oriented data science ethics courses because the reading lists and/or assignments that students in the course are expected to produce are (more) align more with a data science course (i.e., focus on technical approaches or solutions).</p>
<hr>
<section id="data-science-ethics-by-yale-university" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="data-science-ethics-by-yale-university"><span class="header-section-number">2.1</span> Data Science Ethics by Yale University</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background-8" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="background-8"><span class="header-section-number">2.1.1</span> Background</h3>
<p>This course is run by Yale University’s Department of Statistics and Data Science. The faculty instructor is Elisa Celis, who is an assistant professor of Statistics and Data Science. The class is intended for undergraduates. The formal prerequisites for this class are probability and statistics as well as a data analysis course. Furthermore, prior coursework in AI/ML/Algorithms and Ethics/Philosophy is recommended <span class="citation" data-cites="Yale-syllabus">(<a href="#ref-Yale-syllabus" role="doc-biblioref">Celis, 2019</a>)</span>.</p>
</section>
<section id="course-outcomes-4" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="course-outcomes-4"><span class="header-section-number">2.1.2</span> Course Outcomes</h3>
<p>The following are taken from the “Course Learning Objectives” section of <span class="citation" data-cites="Yale-syllabus">Celis (<a href="#ref-Yale-syllabus" role="doc-biblioref">2019</a>)</span>.</p>
<ul>
<li><p>Students develop fluency in the key technical, ethical, policy, and legal terms and concepts related to data science.</p></li>
<li><p>Students learn about algorithmic and data-driven approaches for mitigating biases in AI/ML systems.</p></li>
<li><p>Students reason through problems with no clear answer in a systematic manner, taking and defending different viewpoints, and justifying your conclusions in a rigorous manner.</p></li>
<li><p>Students improve their writing and communication skills both with a technical and lay audience.</p></li>
<li><p>Students listen, understand and communicate with people of varying opinions, viewpoints, and ideas.</p></li>
</ul>
</section>
<section id="course-topics-8" class="level3" data-number="2.1.3">
<h3 data-number="2.1.3" class="anchored" data-anchor-id="course-topics-8"><span class="header-section-number">2.1.3</span> Course Topics</h3>
<ul>
<li><p>Data Collection and Representation and Privacy via subtopics such as Data Sampling and Collection, Managing Datasets Responsibility and Data Cannibalism, the Goal(s) of Data Science, Inference and Privacy, and Re-Identification of Data.</p></li>
<li><p>Machine Bias via subtopics such as Characterizing Machine Bias, Bias versus Correlation versus Causation, Understanding Fairness and Discrimination, Trade-offs between Data Science versus and Human Agents.</p></li>
<li><p>Solutions to Bias via Algorithmic Fairness via subtopics such as Preprocessing Approaches and Debiasing Datasets, Impossibility Results, In-Processing Approaches to Fairness, Fairness in Deep Learning, and Representative Fairness.</p></li>
<li><p>Social Implications and Feedback Loops via subtopics such as Polarization and Feedback Loops, Algorithmic Persuasion, Employment, Advertising, Opportunity, Understanding “Who is” Data Science.</p></li>
<li><p>Controlling Machine Learning Systems via subtopics such as Transparency, Explainability/Interpretability, Accountability, Auditing Algorithms.</p></li>
</ul>
</section>
</div>
</div>
</div>
<hr>
</section>
<section id="computing-ethics-and-society-by-northwestern-university" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="computing-ethics-and-society-by-northwestern-university"><span class="header-section-number">2.2</span> Computing, Ethics, and Society by Northwestern University</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background-9" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="background-9"><span class="header-section-number">2.2.1</span> Background</h3>
<p>This course is run by Northwestern University’s Computer Science Department in the School of Engineering. The course is taught by Sarah Van Wart, an assistant professor of instruction in Computer Science and Engineering. The course has no formal prerequisites <span class="citation" data-cites="Northwestern-Syllabus">(<a href="#ref-Northwestern-Syllabus" role="doc-biblioref">Wart, 2021</a>)</span>.</p>
</section>
<section id="course-outcomes-5" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="course-outcomes-5"><span class="header-section-number">2.2.2</span> Course Outcomes</h3>
<p>The following is taken from the “Course Learning Goals” section of <span class="citation" data-cites="Northwestern-Syllabus">Wart (<a href="#ref-Northwestern-Syllabus" role="doc-biblioref">2021</a>)</span>.</p>
<ul>
<li><p>Students recognize the impact of one’s own assumptions, biases, and experiences.</p></li>
<li><p>Students identify (and question) dominant/normative ways of thinking about computing and technology.</p></li>
<li><p>Students understand some of the underlying concepts that power AI and the internet.</p></li>
<li><p>Students develop a framework for thinking about the relationship between technology and society.</p></li>
<li><p>Students consider how to participate in a world that is heavily mediated by computing.</p></li>
</ul>
</section>
<section id="course-topics-9" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="course-topics-9"><span class="header-section-number">2.2.3</span> Course Topics</h3>
<p>These are based on “Schedule” listed on <span class="citation" data-cites="Northwestern-Syllabus">Wart (<a href="#ref-Northwestern-Syllabus" role="doc-biblioref">2021</a>)</span>.</p>
<ul>
<li><p>Morality, Ethics, and Human Values: Humans’ relationship to morality, understanding fundamental ethical frameworks such as Utilitarianism, Libertarianism, and Kantian ethics.</p></li>
<li><p>Theories of Technology and Society: Understanding the relationship between human values and technology specifically with respect to race and social categories, media representation, surveillance, technological benevolence, and the role of classification systems in perpetuating systematic injustices.</p></li>
<li><p>Computing Infrastructures: Big Data, Surveillance, AI, Content Moderation on Platforms, Business Models of Platforms, and combining these with normative values discussed earlier in the class.</p></li>
</ul>
</section>
</div>
</div>
</div>
<hr>
</section>
<section id="special-topics-in-data-science-responsible-data-science-by-new-york-university" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="special-topics-in-data-science-responsible-data-science-by-new-york-university"><span class="header-section-number">2.3</span> Special Topics in Data Science: Responsible Data Science by New York University</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background-10" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="background-10"><span class="header-section-number">2.3.1</span> Background</h3>
<p>This course is run by New York University’s Center for Data Science. It is taught by Julia Stoyanovich, who is an assistant professor of Data Science, Computer Science, and Engineering. The course has formal prerequisites of either Introduction to Data Science or Introduction to Computer Science or similar <span class="citation" data-cites="NYU-Reading">(<a href="#ref-NYU-Reading" role="doc-biblioref">Stoyanovich, 2019a</a>)</span>.</p>
</section>
<section id="course-outcomes-6" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="course-outcomes-6"><span class="header-section-number">2.3.2</span> Course Outcomes</h3>
<p>The following is taken from the “Learning Objectives” section of <span class="citation" data-cites="NYU-Syllabus">Stoyanovich (<a href="#ref-NYU-Syllabus" role="doc-biblioref">2019b</a>)</span>.</p>
<ul>
<li><p>Students can construct an end-to-end case study that illustrates the role of data science in society.</p></li>
<li><p>Students can explain the ethical and/or legal constraints in the collection and sharing of data according to a framework of the student’s choice.</p></li>
<li><p>Students can implement a computer program that applies anonymization and privacy techniques to a dataset, and explain the trade-offs with utility.</p></li>
<li><p>Students can articulate the differences between various interpretations of algorithmic fairness, and relate these interpretations to the points of view of different stakeholders.</p></li>
<li><p>Students can implement a computer program that audits a black-box classifier.</p></li>
</ul>
</section>
<section id="course-topics-10" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="course-topics-10"><span class="header-section-number">2.3.3</span> Course Topics</h3>
<ul>
<li><p>Algorithmic Fairness</p></li>
<li><p>Causality in Algorithms (and its Relationship to Algorithmic Fairness)</p></li>
<li><p>Anonymity and Privacy in Data Science</p></li>
<li><p>The Trade-off between Privacy and Utility</p></li>
<li><p>Profiling and Particularity</p></li>
<li><p>Algorithmic Transparency</p></li>
<li><p>Data Cleaning</p></li>
<li><p>Legal frameworks, Codes of Ethics, and Personal Responsibility around Data Science</p></li>
<li><p>Civil Rights, Predictive Policing, and Criminal Justice.</p></li>
</ul>
</section>
</div>
</div>
</div>
<hr>
</section>
<section id="ethical-and-social-issues-in-ai-by-cornell-university" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="ethical-and-social-issues-in-ai-by-cornell-university"><span class="header-section-number">2.4</span> Ethical and Social Issues in AI by Cornell University</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background-11" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="background-11"><span class="header-section-number">2.4.1</span> Background</h3>
<p>This course is run by Cornell University’s Computer Science Department. The faculty instructors are Joseph Halpern and Bart Selman, who are both Professors of Computer Science. The course is meant for undergraduates and there are no formal prerequisites for the course. Additionally, it is worth noting that this course is offered only as a Pass/No Credit discussion; there are no assignments beyond “active participation” in the class discussions <span class="citation" data-cites="Cornell-AI">(<a href="#ref-Cornell-AI" role="doc-biblioref">Halpern &amp; Selman, 2017</a>)</span>.</p>
</section>
<section id="course-outcomes-7" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="course-outcomes-7"><span class="header-section-number">2.4.2</span> Course Outcomes</h3>
<p>The following is extrapolated from the required readings and abstracts listed in <span class="citation" data-cites="Cornell-AI">Halpern &amp; Selman (<a href="#ref-Cornell-AI" role="doc-biblioref">2017</a>)</span>.</p>
<ul>
<li><p>Students understand some of the key ethical issues that are associated with developing and employing algorithmic technologies.</p></li>
<li><p>Students foresee some of the potential ethical and social issues facing the development and (widespread) employment of algorithmic technologies.</p></li>
<li><p>Students develop their ability to use philosophical language/frameworks to approach issues in AI.</p></li>
<li><p>Students learn how to engage in discussions of the ethical and social issues of AI, where there are various stakeholders to consider.</p></li>
</ul>
</section>
<section id="course-topics-11" class="level3" data-number="2.4.3">
<h3 data-number="2.4.3" class="anchored" data-anchor-id="course-topics-11"><span class="header-section-number">2.4.3</span> Course Topics</h3>
<p>The following is extrapolated from the required readings and abstracts listed in <span class="citation" data-cites="Cornell-AI">Halpern &amp; Selman (<a href="#ref-Cornell-AI" role="doc-biblioref">2017</a>)</span>.</p>
<ul>
<li><p>Future of AI: Laying out the Benefits and Risks</p></li>
<li><p>Inherent Trade-offs in Algorithmic Fairness</p></li>
<li><p>Interpretable AI</p></li>
<li><p>Computational Ethics for AI</p></li>
<li><p>The Relationship between Humans and Machines in the Workplace</p></li>
<li><p>The Ethics of Robotics, Autonomy, Embodiment, and Anthropomorphism</p></li>
<li><p>Moral Responsibility, Blameworthiness, and Intention of AI</p></li>
</ul>
</section>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="miscellaneous-courses" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Miscellaneous Courses</h1>
<p>There are courses that do not fit well into philosophy or data science oriented data science ethics courses. Some of these courses are more policy-oriented, whereas others have a science, technology, and society (STS) flavor to them.</p>
<hr>
<section id="ethics-public-policy-and-technological-change-by-stanford-university" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="ethics-public-policy-and-technological-change-by-stanford-university"><span class="header-section-number">3.1</span> Ethics, Public Policy, and Technological Change by Stanford University</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background-12" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="background-12"><span class="header-section-number">3.1.1</span> Background</h3>
<p>This course in run by Stanford University’s Department of Computer Science. The course instructors are Rob Reich (Professor of Political Science), Mehran Sahami (Professor of Computer Science and Engineering), and Jeremy Weinstein (Professor of Political Science). The course is meant for undergraduates and it has no formal prerequisites <span class="citation" data-cites="Stanford-Syllabus">(<a href="#ref-Stanford-Syllabus" role="doc-biblioref">Reich, Sahami, &amp; Weinstein, 2023</a>)</span>.</p>
</section>
<section id="course-outcomes-8" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="course-outcomes-8"><span class="header-section-number">3.1.2</span> Course Outcomes</h3>
<p>The following is extrapolated from the “Course Description” section and required readings of <span class="citation" data-cites="Stanford-Syllabus">Reich et al. (<a href="#ref-Stanford-Syllabus" role="doc-biblioref">2023</a>)</span>.</p>
<ul>
<li><p>Students integrate perspectives from computer science, philosophy, and social science to robustly and holistically examine the impact of technology on humans and societies.</p></li>
<li><p>Students critically reflect on their role as enablers and shapers of technological change in society.</p></li>
<li><p>Students will learn how to engage with students across different disciplines in discussions about the ethical and socio-political dimensions of technologies.</p></li>
</ul>
</section>
<section id="course-topics-12" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="course-topics-12"><span class="header-section-number">3.1.3</span> Course Topics</h3>
<ul>
<li><p>Algorithmic Decision-making</p></li>
<li><p>The Political Economy of Technology</p></li>
<li><p>Data Collection, Privacy, and Civil Liberties</p></li>
<li><p>Artificial Intelligence and Autonomous Systems</p></li>
<li><p>Power of Private Platforms</p></li>
<li><p>Blockchain and Decentralized Technical Architectures</p></li>
</ul>
<p><em>Each topic is broken down into 6 sub-modules: Promise and Perils, Technical Deep Dive, Rights and Responsibilities, Moderated Discussion with Experts, Tensions and Trade-offs via a Case Study, and Making Product/System/Policy Choices in Light of these Trade-offs</em></p>
</section>
</div>
</div>
</div>
<hr>
</section>
<section id="human-contexts-and-ethics-of-data-by-the-university-of-california-berkeley" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="human-contexts-and-ethics-of-data-by-the-university-of-california-berkeley"><span class="header-section-number">3.2</span> Human Contexts and Ethics of Data by the University of California, Berkeley</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background-13" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="background-13"><span class="header-section-number">3.2.1</span> Background</h3>
<p>This course is run by University of California, Berkeley’s College of Computing, Data Science, and Society (and cross-listed by the History and Science Technology and Society department). This course’s faculty instructors are Margo Boenig-Lipstin, who is the Director of Human Context and Ethics, and Ari Edmundson, who is a Lecturer in UC Berkeley’s Data Science Undergraduate Studies Program. The course has no formal prerequisites <span class="citation" data-cites="Berkeley-Syllabus">(<a href="#ref-Berkeley-Syllabus" role="doc-biblioref">Boenig-Lipstin &amp; Edmundson, 2020</a>)</span>.</p>
</section>
<section id="course-outcomes-9" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="course-outcomes-9"><span class="header-section-number">3.2.2</span> Course Outcomes</h3>
<p>The following is taken from the “Scope and Objectives” section of <span class="citation" data-cites="Berkeley-Syllabus">Boenig-Lipstin &amp; Edmundson (<a href="#ref-Berkeley-Syllabus" role="doc-biblioref">2020</a>)</span>.</p>
<ul>
<li><p>Students understand the challenge and importance of doing ethical data science amid shifting definitions of human subjects, consent, and privacy.</p></li>
<li><p>Students grapple with the changing relationship between data, democracy, and law.</p></li>
<li><p>Students understand the role of data analytics in how corporations and governments provide public goods such as health and security to citizens.</p></li>
<li><p>Students explore technologies like sensors, machine learning, and artificial intelligence and how they are changing the landscapes of labor, industry, and city life.</p></li>
<li><p>Students reflect on the implications of data for how the public and varied scientific disciplines <em>know</em> the world.</p></li>
</ul>
</section>
<section id="course-topics-13" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3" class="anchored" data-anchor-id="course-topics-13"><span class="header-section-number">3.2.3</span> Course Topics</h3>
<ul>
<li><p>The History of Datafication</p></li>
<li><p>Data Futures: Past and Present</p></li>
<li><p>Characterizations of Data and Data Science</p></li>
<li><p>(Ethically) Responsible Data Science</p></li>
<li><p>Data Shaping Identities</p></li>
<li><p>Populations and States</p></li>
<li><p>Surveillance and Security</p></li>
<li><p>Predictive Policing</p></li>
<li><p>Making Arguments with Data</p></li>
<li><p>Choice, Influence, Manipulation, and Governance</p></li>
<li><p>Algorithmic Sentencing</p></li>
<li><p>Data and Democracy</p></li>
<li><p>Data’s Influence on Scientific Research</p></li>
<li><p>Machines and Industry</p></li>
<li><p>The Ethos of Making</p></li>
</ul>
</section>
</div>
</div>
</div>
<hr>
</section>
<section id="the-ethics-and-governance-of-artificial-intelligence-by-the-massachusetts-institute-of-technology" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="the-ethics-and-governance-of-artificial-intelligence-by-the-massachusetts-institute-of-technology"><span class="header-section-number">3.3</span> The Ethics and Governance of Artificial Intelligence by the Massachusetts Institute of Technology</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background-14" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="background-14"><span class="header-section-number">3.3.1</span> Background</h3>
<p>This course is a Cross-Disciplinary course run by the Massachusetts Institute of Technology. The faculty instructors are Joi Ito, who is a Professor of Practice in Media Arts and Science, and Jonathan Zittrain, who is a Professor of International Law, Computer Science, and Public Policy. The course is meant for graduate students and there are no formal prerequisites <span class="citation" data-cites="MIT-Syllabus">(<a href="#ref-MIT-Syllabus" role="doc-biblioref">Ito &amp; Zittrain, 2018</a>)</span>.</p>
</section>
<section id="course-outcomes-10" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="course-outcomes-10"><span class="header-section-number">3.3.2</span> Course Outcomes</h3>
<p>The following is extrapolated from the “Course Description” section and course readings listed on <span class="citation" data-cites="MIT-Syllabus">Ito &amp; Zittrain (<a href="#ref-MIT-Syllabus" role="doc-biblioref">2018</a>)</span>.</p>
<ul>
<li><p>Students investigate the implications of emerging technologies (with an emphasis on the development and deployment of AI) from a cross-disciplinary perspective.</p></li>
<li><p>Students grapple with complex issues surrounding AI such as how to balance regulation and innovation, how AI influences the dissemination of information, and questions related to individual rights.</p></li>
<li><p>Students analyze socio-political perspectives related to AI case studies in private corporations, labor, and governance.</p></li>
</ul>
</section>
<section id="course-topics-14" class="level3" data-number="3.3.3">
<h3 data-number="3.3.3" class="anchored" data-anchor-id="course-topics-14"><span class="header-section-number">3.3.3</span> Course Topics</h3>
<ul>
<li><p>Machine Learning and Philosophy of Mind</p></li>
<li><p>Algorithmic Opacity</p></li>
<li><p>Autonomy, System Design, Agency, and Liability</p></li>
<li><p>Algorithmic Bias: with case studies in Risk Assessment, Predictive Policing, Credit Scoring, and Image Recognition</p></li>
<li><p>Ownership, Control, and Access</p></li>
<li><p>Governance, Explainability, Accountability</p></li>
<li><p>Labor, Automation, and Regulation</p></li>
<li><p>Ethics, Morals, and Frontiers</p></li>
</ul>
</section>
</div>
</div>
</div>
<hr>
</section>
<section id="ethics-and-policy-in-data-science-by-cornell-university" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="ethics-and-policy-in-data-science-by-cornell-university"><span class="header-section-number">3.4</span> Ethics and Policy in Data Science by Cornell University</h2>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Course Information
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="background-15" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="background-15"><span class="header-section-number">3.4.1</span> Background</h3>
<p>This course is run by Cornell University’s Department of Information Science. The faculty instructor for the course in Solon Barocas, who is an Adjunct Assistant Professor in the Department of Information Science and Principal Researcher at Microsoft. The course is meant for Masters/Undergraduate students and has no formal prerequisites <span class="citation" data-cites="Cornell-DataScience">(<a href="#ref-Cornell-DataScience" role="doc-biblioref">Barocas, 2017</a>)</span>.</p>
</section>
<section id="course-outcomes-11" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="course-outcomes-11"><span class="header-section-number">3.4.2</span> Course Outcomes</h3>
<p>The following is extrapolated from the “Course Description and Objectives” section of <span class="citation" data-cites="Cornell-DataScience">Barocas (<a href="#ref-Cornell-DataScience" role="doc-biblioref">2017</a>)</span>.</p>
<ul>
<li><p>Students can recognize where and understand why ethical issues and policy questions can arise when applying data science to real world problems.</p></li>
<li><p>Students develop fluency in key technical, ethical, policy, and legal terms and concepts that are relevant to a normative assessment of data science and gain exposure to legal scholarship and policy documents that will help them understand the current regulatory environment and potential future environments.</p></li>
<li><p>Students develop their ability to bring analytic and technical precision to normative debates about the role that data science, machine learning, and artificial intelligence play in consequential decision-making in commerce, employment, finance, healthcare, education, policing, and other areas.</p></li>
<li><p>Students will develop tools to conceptualize, measure, and mitigate bias in data-driven decision-making, to audit and evaluate models, and render these analytic tools more interpretable and their determinations more explainable.</p></li>
</ul>
</section>
<section id="course-topics-15" class="level3" data-number="3.4.3">
<h3 data-number="3.4.3" class="anchored" data-anchor-id="course-topics-15"><span class="header-section-number">3.4.3</span> Course Topics</h3>
<ul>
<li><p>Characterizing Data and the Importance of Data Science Ethics</p></li>
<li><p>Algorithmic Bias and Exclusion</p></li>
<li><p>The Social Science of Discrimination</p></li>
<li><p>How Machines Learn to Discriminate</p></li>
<li><p>Auditing Algorithms</p></li>
<li><p>Formalizing and Enforcing Fairness in Machine Learning</p></li>
<li><p>Profiling and Particularity</p></li>
<li><p>Allocative to Representational Harms</p></li>
<li><p>Transparency and Due Process</p></li>
<li><p>Interpretability in Machine Learning</p></li>
<li><p>The Value of Explanation</p></li>
<li><p>Privacy</p></li>
<li><p>Price Discrimination</p></li>
<li><p>Case Studies with Insurance</p></li>
<li><p>Algorithmic Persuasion and Manipulation</p></li>
<li><p>Case Studies with Hiring</p></li>
</ul>
</section>
</div>
</div>
</div>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-Cornell-DataScience" class="csl-entry" role="listitem">
Barocas, S. (2017). <em>INFO 4270: Ethics and policy in data science</em>. Retrieved from <a href="https://docs.google.com/document/d/1GV97qqvjQNvyM2I01vuRaAwHe9pQAZ9pbP7KkKveg1o/edit">https://docs.google.com/document/d/1GV97qqvjQNvyM2I01vuRaAwHe9pQAZ9pbP7KkKveg1o/edit</a>
</div>
<div id="ref-Berkeley-Syllabus" class="csl-entry" role="listitem">
Boenig-Lipstin, M., &amp; Edmundson, A. (2020). <em>Hist C184D/STS C104 human contexts and ethics of data</em>. Retrieved from <a href="https://docs.google.com/document/d/1aRSkK0FmyaWCIsFq4MCbTrP2yGmP_rTPQ9MJLzdwWnc/edit">https://docs.google.com/document/d/1aRSkK0FmyaWCIsFq4MCbTrP2yGmP_rTPQ9MJLzdwWnc/edit</a>
</div>
<div id="ref-Liam-Kofi-syllabus" class="csl-entry" role="listitem">
Bright, L. K. (2022). <em>Ethics in AI syllabus</em>. Retrieved from <a href="https://philpeople.org/teaching_materials/3554/download">https://philpeople.org/teaching_materials/3554/download</a>
</div>
<div id="ref-Yale-syllabus" class="csl-entry" role="listitem">
Celis, E. (2019). <em>Data science ethics syllabus</em>. Retrieved from <a href="https://datascienceethics.wordpress.com/the-course/syllabus/">https://datascienceethics.wordpress.com/the-course/syllabus/</a>
</div>
<div id="ref-UCSD-DataEthics" class="csl-entry" role="listitem">
Danks, D. (2023). <em>Data ethics (PHIL 174)</em>. Retrieved from <a href="https://philosophy.ucsd.edu/courses/course-syllabus/wi23/PHIL174.pdf">https://philosophy.ucsd.edu/courses/course-syllabus/wi23/PHIL174.pdf</a>
</div>
<div id="ref-CMU-DataAnalytics" class="csl-entry" role="listitem">
Danks, D., &amp; Fazelpour, S. (2021). <em>Ethics &amp; policy of data analytics</em>. Retrieved from <a href="https://www.heinz.cmu.edu/current-students/courses/94-836/2238/">https://www.heinz.cmu.edu/current-students/courses/94-836/2238/</a>
</div>
<div id="ref-UF-syllabus" class="csl-entry" role="listitem">
Grant, D. G. (2021). <em>Ethics, data, and technology (PHI 3681)</em>. Retrieved from <a href="https://phil.ufl.edu/wp-content/uploads/sites/145/2022/01/PHI3681-Grant-Syllabus-2021-28-12.pdf">https://phil.ufl.edu/wp-content/uploads/sites/145/2022/01/PHI3681-Grant-Syllabus-2021-28-12.pdf</a>
</div>
<div id="ref-Cornell-AI" class="csl-entry" role="listitem">
Halpern, J., &amp; Selman, B. (2017). <em>CS 4732: Ethical and social issues in AI (spring, 2017)</em>. Retrieved from <a href="https://www.cs.cornell.edu/courses/cs4732/2017sp/">https://www.cs.cornell.edu/courses/cs4732/2017sp/</a>
</div>
<div id="ref-MIT-Syllabus" class="csl-entry" role="listitem">
Ito, J., &amp; Zittrain, J. (2018). <em>The ethics and governance of artificial intelligence</em>. Retrieved from <a href="https://dam-prod.media.mit.edu/x/2018/02/07/Ethics%20and%20Governance%20of%20AI%20S18%20.pdf">https://dam-prod.media.mit.edu/x/2018/02/07/Ethics%20and%20Governance%20of%20AI%20S18%20.pdf</a>
</div>
<div id="ref-CMU-ML-reading" class="csl-entry" role="listitem">
Lipton, Z. (2023a). Retrieved from <a href="https://github.com/acmi-lab/cmu-10721-philosophy-machine-intelligence/blob/main/schedule.md">https://github.com/acmi-lab/cmu-10721-philosophy-machine-intelligence/blob/main/schedule.md</a>
</div>
<div id="ref-CMU-ML-syllabus" class="csl-entry" role="listitem">
Lipton, Z. (2023b). <em>Carnegie mellon university 10721: Philosophical foundations of machine intelligence 2023</em>. Retrieved from <a href="https://github.com/acmi-lab/cmu-10721-philosophy-machine-intelligence/tree/main">https://github.com/acmi-lab/cmu-10721-philosophy-machine-intelligence/tree/main</a>
</div>
<div id="ref-Rice-Syllabus" class="csl-entry" role="listitem">
Petrick, E. (2021). <em>DSCI 305: Data, ethics, and society</em>. Retrieved from <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwjBqtWbooD_AhUhIzQIHXWLD_c4ChAWegQIBhAB&amp;url=https%3A%2F%2Festher.rice.edu%2Fselfserve%2F!bwzkpsyl.v_viewDoc%3Fterm%3D202120%26crn%3D23021%26type%3DSYLLABUS&amp;usg=AOvVaw1zimMugXOdwaI0SYtmBHVE">https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwjBqtWbooD_AhUhIzQIHXWLD_c4ChAWegQIBhAB&amp;url=https%3A%2F%2Festher.rice.edu%2Fselfserve%2F!bwzkpsyl.v_viewDoc%3Fterm%3D202120%26crn%3D23021%26type%3DSYLLABUS&amp;usg=AOvVaw1zimMugXOdwaI0SYtmBHVE</a>
</div>
<div id="ref-Stanford-Syllabus" class="csl-entry" role="listitem">
Reich, R., Sahami, M., &amp; Weinstein, J. (2023). <em>CS182: Ethics, public policy, and technological change</em>. Retrieved from <a href="https://web.stanford.edu/class/cs182/">https://web.stanford.edu/class/cs182/</a>
</div>
<div id="ref-Swarthmore-Syllabus" class="csl-entry" role="listitem">
Soni, A., &amp; Thomason, K. K. (2019). <em>FYS: Ethics and technology (PHIL 07/CPSC 15) syllabus</em>. Retrieved from <a href="https://works.swarthmore.edu/cgi/viewcontent.cgi?article=1027&amp;context=dev-dhgrants">https://works.swarthmore.edu/cgi/viewcontent.cgi?article=1027&amp;context=dev-dhgrants</a>
</div>
<div id="ref-NYU-Syllabus" class="csl-entry" role="listitem">
Stoyanovich, J. (2019b). <em>DS-GA 3001.009: Special topics in data science: Responsible data science</em>. Retrieved from <a href="https://dataresponsibly.github.io/courses/documents/spring19/Syllabus_DS-GA-3001.009_SP_2019.pdf">https://dataresponsibly.github.io/courses/documents/spring19/Syllabus_DS-GA-3001.009_SP_2019.pdf</a>
</div>
<div id="ref-NYU-Reading" class="csl-entry" role="listitem">
Stoyanovich, J. (2019a). <em>DS-GA 3001.009: Special topics in data science: Responsible data science</em>. Retrieved from <a href="https://dataresponsibly.github.io/courses/spring19/">https://dataresponsibly.github.io/courses/spring19/</a>
</div>
<div id="ref-LSE-syllabus" class="csl-entry" role="listitem">
Vredenburgh, K., Boyle, A., Voorhoeve, A., &amp; Romero, P. (2023). <em>The ethics of data and artificial intelligence (ME102)</em>. Retrieved from <a href="https://www.lse.ac.uk/ss-asset-library/course-outlines/2023/ME102-Course-Outline-2023.pdf">https://www.lse.ac.uk/ss-asset-library/course-outlines/2023/ME102-Course-Outline-2023.pdf</a>
</div>
<div id="ref-Northwestern-Syllabus" class="csl-entry" role="listitem">
Wart, S. V. (2021). <em>Computing, ethics, &amp; society</em>. Retrieved from <a href="https://nu-tech-ethics.github.io/winter2021/syllabus/">https://nu-tech-ethics.github.io/winter2021/syllabus/</a>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/scolando\.github\.io\/data-science-ethics\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2024, <a href="https://scolando.github.io">Sara Colando</a> and <a href="https://hardin47.netlify.app">Jo Hardin</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://github.com/scolando/data-science-ethics">
<p><iconify-icon role="img" inline="" icon="mdi:github" aria-label="Icon github from mdi Iconify.design set." title="Icon github from mdi Iconify.design set."></iconify-icon> Source Code</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://github.com/scolando/data-science-ethics/issues/new">
<p>Report an Issue</p>
</a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>